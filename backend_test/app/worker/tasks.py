# app/worker/tasks.py

from typing import List

from sqlalchemy.util import NoneType
from app.crud import crud_sqlite
from app.crud.crud_graph import create_entity, create_relation, create_document_entity_relation, create_resource_node
from app.schemas.entity import EntityCreate, RelationCreate, DocumentEntityRelationCreate
from app.schemas.resource import ResourceCreate
from app.db.sqlite_session import SessionLocal
from app.db.neo4j_session import get_neo4j_driver
import random
import time

def _run_single_document_extraction(document_id: int, db_session, neo4j_driver, graph_id: str = None, parent_id: str = None):
    """
    è¿™æ˜¯ä¸€ä¸ªå†…éƒ¨è¾…åŠ©å‡½æ•°ï¼Œè´Ÿè´£å¤„ç†å•ä¸ªæ–‡æ¡£çš„å®Œæ•´æµç¨‹ã€‚
    æ¨¡æ‹Ÿæ–‡æ¡£åˆ†å—ã€å®ä½“å…³ç³»æå–å’ŒNeo4jå­˜å‚¨
    """
    try:
        print(f"ğŸ“„ å¼€å§‹å¤„ç†å­ä»»åŠ¡ï¼šæ–‡æ¡£ ID: {document_id}")
        crud_sqlite.update_document_status(db_session, document_id=document_id, status="processing")
        
        document = crud_sqlite.get_source_document(db_session, document_id=document_id)
        if not document:
            print(f"âŒ æ–‡æ¡£ ID: {document_id} ä¸å­˜åœ¨")
            return
            
        print(f"ğŸ“– æ–‡æ¡£ä¿¡æ¯: {document.filename} (æ–‡æ¡£ID: {document.id})")
        
        # === 1. æ¨¡æ‹Ÿæ–‡æ¡£åˆ†å— ===
        print("ğŸ”ª å¼€å§‹æ–‡æ¡£åˆ†å—...")
        chunks = _simulate_document_chunking(document.filename)
        print(f"âœ… æ–‡æ¡£åˆ†å—å®Œæˆï¼Œå…±ç”Ÿæˆ {len(chunks)} ä¸ªåˆ†å—")
        
        # === 2. éå†åˆ†å—ï¼Œæå–å®ä½“å’Œå…³ç³» ===
        all_entities = {}  # ç”¨äºå»é‡çš„å®ä½“å­—å…¸
        all_entities_list = []  # ä¿å­˜æ‰€æœ‰åŸå§‹å®ä½“ï¼ˆåŒ…å«chunk_idï¼‰
        all_relations = []
        
        for i, chunk in enumerate(chunks, 1):
            chunk_id = f"{document.id}_chunk_{i}"  # ç”Ÿæˆåˆ†å—ID
            print(f"ğŸ” å¤„ç†ç¬¬ {i} ä¸ªåˆ†å—: {chunk[:50]}...")
            
            # æ¨¡æ‹Ÿå®ä½“æå–
            entities = _simulate_entity_extraction(chunk, chunk_id)
            print(f"  ğŸ“Š æå–åˆ° {len(entities)} ä¸ªå®ä½“: {[e['name'] for e in entities]}")
            
            # æ¨¡æ‹Ÿå…³ç³»æå–
            relations = _simulate_relation_extraction(entities)
            print(f"  ğŸ”— æå–åˆ° {len(relations)} ä¸ªå…³ç³»")
            
            # æ”¶é›†æ‰€æœ‰åŸå§‹å®ä½“ï¼ˆä¿ç•™chunk_idä¿¡æ¯ï¼‰
            all_entities_list.extend(entities)
            
            # æ”¶é›†å®ä½“ï¼ˆå»é‡ï¼‰
            for entity in entities:
                entity_key = f"{entity['name']}_{entity['entity_type']}"
                if entity_key not in all_entities:
                    all_entities[entity_key] = entity
                else:
                    # å¢åŠ é¢‘æ¬¡
                    all_entities[entity_key]['frequency'] = all_entities[entity_key].get('frequency', 1) + 1
            
            # æ”¶é›†å…³ç³»
            all_relations.extend(relations)
            
            # æ¨¡æ‹Ÿå¤„ç†å»¶æ—¶
            time.sleep(0.5)
        
        # === 3. å®ä½“é“¾æ¥ä¸æ¶ˆæ­§ï¼ˆç®€åŒ–æ¨¡æ‹Ÿï¼‰===
        print("ğŸ”— å¼€å§‹å®ä½“é“¾æ¥ä¸æ¶ˆæ­§...")
        disambiguated_entities = _simulate_entity_disambiguation(all_entities)
        print(f"âœ… å®ä½“æ¶ˆæ­§å®Œæˆï¼Œæœ€ç»ˆå®ä½“æ•°: {len(disambiguated_entities)}")
        
        # === 4. å›¾è°±å…¥åº“ ===
        print("ğŸ’¾ å¼€å§‹å›¾è°±å…¥åº“...")
        
        # éªŒè¯çˆ¶èŠ‚ç‚¹ï¼ˆå¦‚æœæä¾›äº†parent_idï¼‰
        if parent_id:
            from app.crud.crud_graph import get_node_by_id
            parent_node = get_node_by_id(driver=neo4j_driver, node_id=parent_id)
            if not parent_node:
                print(f"âŒ çˆ¶èŠ‚ç‚¹ ID '{parent_id}' ä¸å­˜åœ¨ï¼Œè·³è¿‡æ–‡æ¡£ {document.filename}")
                return
            if parent_node.get("graph_id") != graph_id:
                print(f"âŒ çˆ¶èŠ‚ç‚¹ä¸å±äºå½“å‰å›¾è°±ï¼Œè·³è¿‡æ–‡æ¡£ {document.filename}")
                return
        
        # ä»æ•°æ®åº“è·å–æ–‡æ¡£ä¿¡æ¯ï¼ŒåŒ…æ‹¬èµ„æºç±»å‹
        document = crud_sqlite.get_source_document(db=db_session, document_id=document_id)
        if not document:
            print(f"âŒ æ–‡æ¡£ ID {document_id} ä¸å­˜åœ¨")
            return
        
        # é¦–å…ˆåˆ›å»ºæ–‡æ¡£èµ„æºèŠ‚ç‚¹
        # ç›´æ¥ä½¿ç”¨æ•°æ®åº“ä¸­çš„resource_typeå­—ç¬¦ä¸²å€¼
        resource_create = ResourceCreate(
            filename=document.filename,
            content=document.content,
            type=document.resource_type,
            graph_id=graph_id or "default-graph-id",
            parent_id=parent_id or graph_id or "default-graph-id"
        )
        created_resource = create_resource_node(neo4j_driver, resource_create, document.id)
        print(f"  âœ… åˆ›å»ºæ–‡æ¡£èµ„æºèŠ‚ç‚¹: {document.filename} (ID: {created_resource['id']})")
        
        # æ›´æ–°æ–‡æ¡£-å®ä½“å…³ç³»ä¸­ä½¿ç”¨çš„æ–‡æ¡£IDä¸ºNeo4jä¸­çš„èµ„æºèŠ‚ç‚¹ID
        neo4j_document_id = created_resource['id']
        
        entity_id_mapping = {}
        
        # 4.1 åˆ›å»ºå®ä½“èŠ‚ç‚¹
        for entity_data in disambiguated_entities.values():
            # æ”¶é›†è¯¥å®ä½“çš„æ‰€æœ‰chunk_ids
            chunk_ids = []
            for orig_entity in all_entities_list:
                if orig_entity["name"] == entity_data["name"] and orig_entity.get("chunk_id"):
                    chunk_ids.append(orig_entity["chunk_id"])
            
            entity_create = EntityCreate(
                name=entity_data['name'],
                entity_type=entity_data['entity_type'],
                description=entity_data.get('description'),
                graph_id=graph_id or "default-graph-id",
                chunk_ids=list(set(chunk_ids)),  # å»é‡
                document_id=document.id
            )
            
            try:
                created_entity = create_entity(neo4j_driver, entity_create)
                entity_id_mapping[f"{entity_data['name']}_{entity_data['entity_type']}"] = created_entity['id']
                print(f"  âœ… åˆ›å»ºå®ä½“: {entity_data['name']} ({entity_data['entity_type']}) - åˆ†å—: {chunk_ids}")
                
                # åˆ›å»ºæ–‡æ¡£-å®ä½“å…³ç³»ï¼ˆä½¿ç”¨Neo4jèµ„æºèŠ‚ç‚¹IDï¼‰
                doc_entity_relation = DocumentEntityRelationCreate(
                    document_id=neo4j_document_id,  # ç›´æ¥ä½¿ç”¨Neo4jèµ„æºèŠ‚ç‚¹çš„UUID
                    entity_id=created_entity["id"],
                    relation_type="HAS_ENTITY"
                )
                create_document_entity_relation(neo4j_driver, doc_entity_relation)
            except Exception as e:
                print(f"  âŒ åˆ›å»ºå®ä½“å¤±è´¥: {entity_data['name']} - {e}")
        
        # 4.2 åˆ›å»ºå…³ç³»
        created_relations_count = 0
        for relation_data in all_relations:
            source_key = f"{relation_data['source_name']}_{relation_data['source_type']}"
            target_key = f"{relation_data['target_name']}_{relation_data['target_type']}"
            
            if source_key in entity_id_mapping and target_key in entity_id_mapping:
                relation_create = RelationCreate(
                    source_entity_id=entity_id_mapping[source_key],
                    target_entity_id=entity_id_mapping[target_key],
                    relation_type=relation_data['relation_type'],
                    description=relation_data.get('description'),
                    confidence=relation_data.get('confidence', 0.8),
                    graph_id=graph_id or "default-graph-id"
                )
                
                try:
                    created_relation = create_relation(neo4j_driver, relation_create)
                    if created_relation:
                        created_relations_count += 1
                        print(f"  âœ… åˆ›å»ºå…³ç³»: {relation_data['source_name']} -[{relation_data['relation_type']}]-> {relation_data['target_name']}")
                except Exception as e:
                    print(f"  âŒ åˆ›å»ºå…³ç³»å¤±è´¥: {relation_data['source_name']} -> {relation_data['target_name']} - {e}")
        
        print(f"ğŸ’¾ å›¾è°±å…¥åº“å®Œæˆï¼åˆ›å»ºäº† {len(entity_id_mapping)} ä¸ªå®ä½“ï¼Œ{created_relations_count} ä¸ªå…³ç³»")
        
        crud_sqlite.update_document_status(db_session, document_id=document_id, status="completed")
        print(f"ğŸ‰ å­ä»»åŠ¡æˆåŠŸï¼šæ–‡æ¡£ ID: {document_id} å¤„ç†å®Œæ¯•ï¼")
        
    except Exception as e:
        crud_sqlite.update_document_status(db_session, document_id=document_id, status="failed")
        print(f"âŒ å­ä»»åŠ¡å¤±è´¥ï¼šå¤„ç†æ–‡æ¡£ ID: {document_id} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        # å¯ä»¥é€‰æ‹©åœ¨è¿™é‡ŒæŠ›å‡ºå¼‚å¸¸æ¥ä¸­æ–­æ•´ä¸ªæ‰¹å¤„ç†ï¼Œæˆ–è€…ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª
        # raise e 

def run_batch_knowledge_extraction(document_ids: List[int], graph_id: str = NoneType, parent_id: str = None):
    """
    è¿™æ˜¯æ–°çš„ã€åœ¨åå°è¿è¡Œçš„ã€æ‰¹é‡ã€‘çŸ¥è¯†æå–ä¸»å‡½æ•°ã€‚
    å®ƒä¼šæŒ‰é¡ºåºä¸²è¡Œå¤„ç†åˆ—è¡¨ä¸­çš„æ¯ä¸€ä¸ªæ–‡æ¡£ã€‚
    
    Args:
        document_ids: æ–‡æ¡£IDåˆ—è¡¨
        graph_id: å›¾è°±ID
        parent_id: çˆ¶èŠ‚ç‚¹ID
        resource_type: èµ„æºç±»å‹
    """
    print(f"æ‰¹é‡åå°ä»»åŠ¡å¯åŠ¨ï¼šå‡†å¤‡å¤„ç† {len(document_ids)} ä¸ªæ–‡æ¡£ã€‚")
    
    db_session = SessionLocal()
    neo4j_driver_instance = get_neo4j_driver()

    try:
        # åœ¨ä¸€ä¸ªä»»åŠ¡ä¸­ï¼ŒæŒ‰é¡ºåºå¾ªç¯å¤„ç†æ¯ä¸ªæ–‡æ¡£
        for doc_id in document_ids:
            _run_single_document_extraction(
                document_id=doc_id,
                db_session=db_session,
                neo4j_driver=neo4j_driver_instance,
                graph_id=graph_id,
                parent_id=parent_id
            )
        
        print(f"æ‰¹é‡åå°ä»»åŠ¡æˆåŠŸï¼šæ‰€æœ‰æ–‡æ¡£å¤„ç†å®Œæ¯•ã€‚")

    except Exception as e:
        print(f"æ‰¹é‡åå°ä»»åŠ¡å› æŸä¸ªå­ä»»åŠ¡å¤±è´¥è€Œä¸­æ–­: {e}")
    finally:
        db_session.close()


# === æ¨¡æ‹Ÿå‡½æ•°å®ç° ===
def _simulate_document_chunking(document_title: str) -> List[str]:
    """æ¨¡æ‹Ÿæ–‡æ¡£åˆ†å—ï¼Œæ ¹æ®æ–‡æ¡£æ ‡é¢˜ç”Ÿæˆä¸¤ä¸ªæ¨¡æ‹Ÿåˆ†å—"""
    chunks = [
        f"è¿™æ˜¯å…³äº{document_title}çš„ç¬¬ä¸€éƒ¨åˆ†å†…å®¹ã€‚åœ¨è¿™ä¸ªéƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å†ç¨‹ï¼ŒåŒ…æ‹¬æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ç­‰æ ¸å¿ƒæ¦‚å¿µã€‚äººå·¥æ™ºèƒ½å·²ç»æˆä¸ºç°ä»£ç§‘æŠ€å‘å±•çš„é‡è¦é©±åŠ¨åŠ›ï¼Œåœ¨å„ä¸ªé¢†åŸŸéƒ½æœ‰å¹¿æ³›çš„åº”ç”¨ã€‚",
        f"è¿™æ˜¯å…³äº{document_title}çš„ç¬¬äºŒéƒ¨åˆ†å†…å®¹ã€‚æœ¬éƒ¨åˆ†é‡ç‚¹ä»‹ç»äº†çŸ¥è¯†å›¾è°±æŠ€æœ¯åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸçš„åº”ç”¨ã€‚çŸ¥è¯†å›¾è°±é€šè¿‡å®ä½“å’Œå…³ç³»çš„ç»“æ„åŒ–è¡¨ç¤ºï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°ç»„ç»‡å’Œç®¡ç†å¤§è§„æ¨¡çš„çŸ¥è¯†ä¿¡æ¯ï¼Œä¸ºæ™ºèƒ½ç³»ç»Ÿæä¾›å¼ºå¤§çš„æ¨ç†èƒ½åŠ›ã€‚"
    ]
    return chunks


def _simulate_entity_extraction(chunk_text: str, chunk_id: str = None) -> List[dict]:
    """æ¨¡æ‹Ÿå®ä½“æå–ï¼Œæ ¹æ®åˆ†å—å†…å®¹è¿”å›æ¨¡æ‹Ÿçš„å®ä½“åˆ—è¡¨"""
    # æ ¹æ®åˆ†å—å†…å®¹çš„å…³é”®è¯æ¥ç”Ÿæˆä¸åŒçš„å®ä½“
    entities = []
    
    if "äººå·¥æ™ºèƒ½" in chunk_text:
        entities.extend([
            {"name": "äººå·¥æ™ºèƒ½", "entity_type": "æŠ€æœ¯é¢†åŸŸ", "description": "æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„æŠ€æœ¯", "frequency": 1, "chunk_id": chunk_id},
            {"name": "æœºå™¨å­¦ä¹ ", "entity_type": "æŠ€æœ¯æ–¹æ³•", "description": "è®©æœºå™¨ä»æ•°æ®ä¸­å­¦ä¹ çš„æ–¹æ³•", "frequency": 1, "chunk_id": chunk_id},
            {"name": "æ·±åº¦å­¦ä¹ ", "entity_type": "æŠ€æœ¯æ–¹æ³•", "description": "åŸºäºç¥ç»ç½‘ç»œçš„å­¦ä¹ æ–¹æ³•", "frequency": 1, "chunk_id": chunk_id}
        ])
    
    if "çŸ¥è¯†å›¾è°±" in chunk_text:
        entities.extend([
            {"name": "çŸ¥è¯†å›¾è°±", "entity_type": "æŠ€æœ¯é¢†åŸŸ", "description": "ç»“æ„åŒ–çŸ¥è¯†è¡¨ç¤ºæ–¹æ³•", "frequency": 1, "chunk_id": chunk_id},
            {"name": "å®ä½“", "entity_type": "æ¦‚å¿µ", "description": "çŸ¥è¯†å›¾è°±ä¸­çš„åŸºæœ¬å•å…ƒ", "frequency": 1, "chunk_id": chunk_id},
            {"name": "å…³ç³»", "entity_type": "æ¦‚å¿µ", "description": "å®ä½“ä¹‹é—´çš„è¿æ¥", "frequency": 1, "chunk_id": chunk_id},
            {"name": "æ¨ç†èƒ½åŠ›", "entity_type": "èƒ½åŠ›", "description": "åŸºäºçŸ¥è¯†è¿›è¡Œé€»è¾‘æ¨ç†çš„èƒ½åŠ›", "frequency": 1, "chunk_id": chunk_id}
        ])
    
    # æ·»åŠ ä¸€äº›é€šç”¨å®ä½“
    common_entities = [
        {"name": "ç§‘æŠ€å‘å±•", "entity_type": "æ¦‚å¿µ", "description": "æŠ€æœ¯è¿›æ­¥çš„è¿‡ç¨‹", "frequency": 1, "chunk_id": chunk_id},
        {"name": "æ™ºèƒ½ç³»ç»Ÿ", "entity_type": "ç³»ç»Ÿ", "description": "å…·æœ‰æ™ºèƒ½ç‰¹å¾çš„è®¡ç®—æœºç³»ç»Ÿ", "frequency": 1, "chunk_id": chunk_id}
    ]
    entities.extend(common_entities)
    
    # éšæœºé€‰æ‹©3-5ä¸ªå®ä½“è¿”å›
    selected_count = random.randint(3, min(5, len(entities)))
    return random.sample(entities, selected_count)


def _simulate_relation_extraction(entities: List[dict]) -> List[dict]:
    """æ¨¡æ‹Ÿå…³ç³»æå–ï¼Œæ ¹æ®å®ä½“åˆ—è¡¨ç”Ÿæˆæ¨¡æ‹Ÿçš„å…³ç³»"""
    relations = []
    
    if len(entities) < 2:
        return relations
    
    # é¢„å®šä¹‰ä¸€äº›å…³ç³»ç±»å‹
    relation_types = [
        "åŒ…å«", "å±äº", "åº”ç”¨äº", "åŸºäº", "ä¿ƒè¿›", "å®ç°", "æ”¯æŒ", "ä¾èµ–"
    ]
    
    # ç”Ÿæˆ1-3ä¸ªå…³ç³»
    num_relations = random.randint(1, min(3, len(entities) - 1))
    
    for i in range(num_relations):
        # éšæœºé€‰æ‹©ä¸¤ä¸ªä¸åŒçš„å®ä½“
        source_entity = random.choice(entities)
        target_entity = random.choice([e for e in entities if e != source_entity])
        
        relation = {
            "source_name": source_entity["name"],
            "source_type": source_entity["entity_type"],
            "target_name": target_entity["name"],
            "target_type": target_entity["entity_type"],
            "relation_type": random.choice(relation_types),
            "description": f"{source_entity['name']}ä¸{target_entity['name']}ä¹‹é—´çš„å…³ç³»",
            "confidence": round(random.uniform(0.7, 0.95), 2)
        }
        relations.append(relation)
    
    return relations


def _simulate_entity_disambiguation(entities_dict: dict) -> dict:
    """æ¨¡æ‹Ÿå®ä½“æ¶ˆæ­§ï¼Œç®€åŒ–å¤„ç†ï¼Œä¸»è¦æ˜¯åˆå¹¶ç›¸ä¼¼å®ä½“"""
    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šè¿›è¡Œå¤æ‚çš„å®ä½“é“¾æ¥å’Œæ¶ˆæ­§
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œåªæ˜¯è¿”å›åŸå§‹å®ä½“å­—å…¸
    disambiguated = {}
    
    for key, entity in entities_dict.items():
        # ç®€å•çš„æ¶ˆæ­§é€»è¾‘ï¼šå¦‚æœå®ä½“åç§°ç›¸ä¼¼ï¼Œåˆå¹¶é¢‘æ¬¡
        found_similar = False
        for existing_key, existing_entity in disambiguated.items():
            if (
                entity["name"].lower() == existing_entity["name"].lower() and 
                entity["entity_type"] == existing_entity["entity_type"]
            ):
                # åˆå¹¶é¢‘æ¬¡
                existing_entity["frequency"] += entity.get("frequency", 1)
                found_similar = True
                break
        
        if not found_similar:
            disambiguated[key] = entity.copy()
    
    return disambiguated