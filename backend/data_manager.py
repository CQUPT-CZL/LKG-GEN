import os
import json
import uuid
from datetime import datetime
from typing import List, Dict, Any, Optional
from pathlib import Path

class DataManager:
    """æ•°æ®ç®¡ç†å™¨ - ä½¿ç”¨JSONæ–‡ä»¶å­˜å‚¨æ•°æ®"""
    
    def __init__(self, data_dir: str = "data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºå„ä¸ªæ•°æ®ç›®å½•
        self.graphs_dir = self.data_dir / "graphs"
        self.tasks_dir = self.data_dir / "tasks"
        self.categories_dir = self.data_dir / "categories"  # æ–°å¢ï¼šåˆ†ç±»ç›®å½•
        
        # å‘åå…¼å®¹ï¼šä¿ç•™æ—§çš„ç›®å½•å±æ€§
        self.entities_dir = self.data_dir / "ner_output"
        self.relations_dir = self.data_dir / "re_output"
        
        for dir_path in [self.graphs_dir, self.tasks_dir, self.categories_dir, self.entities_dir, self.relations_dir]:
            dir_path.mkdir(exist_ok=True)
            
        # åˆå§‹åŒ–æ ¹åˆ†ç±»
        self._ensure_root_category()
    
    def _load_json(self, file_path: Path) -> Dict[str, Any]:
        """åŠ è½½JSONæ–‡ä»¶"""
        if file_path.exists():
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _save_json(self, data: Dict[str, Any], file_path: Path):
        """ä¿å­˜JSONæ–‡ä»¶"""
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def _get_all_files_data(self, directory: Path) -> List[Dict[str, Any]]:
        """è·å–ç›®å½•ä¸‹æ‰€æœ‰JSONæ–‡ä»¶çš„æ•°æ®"""
        data_list = []
        for file_path in directory.glob("*.json"):
            data = self._load_json(file_path)
            if data:
                data_list.append(data)
        return data_list
    
    def save_graph(self, graph_id: str, graph_data: Dict[str, Any]):
        """ä¿å­˜å›¾è°±æ•°æ®"""
        file_path = self.graphs_dir / f"{graph_id}.json"
        self._save_json(graph_data, file_path)
    
    def _get_graph_name(self, graph_id: str) -> str:
        """è·å–å›¾è°±åç§°ï¼ˆé¿å…å¾ªç¯è°ƒç”¨ï¼‰"""
        file_path = self.graphs_dir / f"{graph_id}.json"
        graph_data = self._load_json(file_path)
        
        if not graph_data:
            raise ValueError(f"å›¾è°± {graph_id} ä¸å­˜åœ¨")
        
        graph_name = graph_data.get('name')
        if not graph_name:
            raise ValueError(f"å›¾è°± {graph_id} æ²¡æœ‰åç§°")
        
        return graph_name
    
    def _get_graph_entities_dir(self, graph_id: str) -> Path:
        """è·å–æŒ‡å®šå›¾è°±çš„å®ä½“ç›®å½• - ä½¿ç”¨ner_pro_outputç›®å½•å­˜å‚¨æœ€ç»ˆæ¶ˆæ­§åçš„å®ä½“"""
        ner_pro_output_dir = self.data_dir / "ner_pro_output" / graph_id
        ner_pro_output_dir.mkdir(parents=True, exist_ok=True)
        return ner_pro_output_dir
    
    def _get_graph_relations_dir(self, graph_id: str) -> Path:
        """è·å–æŒ‡å®šå›¾è°±çš„å…³ç³»ç›®å½• - ä½¿ç”¨re_outputç›®å½•"""
        re_output_dir = self.data_dir / "re_output" / graph_id
        re_output_dir.mkdir(parents=True, exist_ok=True)
        return re_output_dir
    
    def get_graph_entities_file(self, graph_id: str) -> Path:
        """è·å–å›¾è°±çš„æœ€ç»ˆå®ä½“æ–‡ä»¶è·¯å¾„ï¼ˆæ¶ˆæ­§åï¼‰"""
        entities_dir = self._get_graph_entities_dir(graph_id)
        return entities_dir / f"{graph_id}.json"
    
    def get_graph_relations_file(self, graph_id: str) -> Path:
        """è·å–å›¾è°±çš„å…³ç³»æ–‡ä»¶è·¯å¾„"""
        relations_dir = self._get_graph_relations_dir(graph_id)
        return relations_dir / f"{graph_id}.json"
    
    def save_entity(self, entity_id: str, entity_data: Dict[str, Any], graph_id: str = None):
        """ä¿å­˜å®ä½“æ•°æ®åˆ°æŒ‡å®šå›¾è°±ç›®å½•ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰"""
        if graph_id:
            # ä¿å­˜åˆ°å›¾è°±ç‰¹å®šç›®å½•
            graph_entities_dir = self._get_graph_entities_dir(graph_id)
            file_path = graph_entities_dir / f"{entity_id}.json"
        else:
            # å…¼å®¹æ—§ç‰ˆæœ¬ï¼Œä¿å­˜åˆ°å…¨å±€ç›®å½•
            file_path = self.entities_dir / f"{entity_id}.json"
        self._save_json(entity_data, file_path)
    
    def save_relation(self, relation_id: str, relation_data: Dict[str, Any], graph_id: str = None):
        """ä¿å­˜å…³ç³»æ•°æ®åˆ°æŒ‡å®šå›¾è°±ç›®å½•ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰"""
        if graph_id:
            # ä¿å­˜åˆ°å›¾è°±ç‰¹å®šç›®å½•
            graph_relations_dir = self._get_graph_relations_dir(graph_id)
            file_path = graph_relations_dir / f"{relation_id}.json"
        else:
            # å…¼å®¹æ—§ç‰ˆæœ¬ï¼Œä¿å­˜åˆ°å…¨å±€ç›®å½•
            file_path = self.relations_dir / f"{relation_id}.json"
        self._save_json(relation_data, file_path)
    
    def save_graph_entities(self, graph_id: str, entities: List[Dict[str, Any]]):
        """ä¿å­˜å›¾è°±çš„æœ€ç»ˆå®ä½“åˆ—è¡¨ï¼ˆæ¶ˆæ­§åï¼‰åˆ°å•ä¸ªæ–‡ä»¶"""
        entities_file = self.get_graph_entities_file(graph_id)
        self._save_json(entities, entities_file)
        print(f"âœ… å·²ä¿å­˜å›¾è°± {graph_id} çš„ {len(entities)} ä¸ªå®ä½“åˆ° {entities_file}")
    
    def save_graph_relations(self, graph_id: str, relations: List[Dict[str, Any]]):
        """ä¿å­˜å›¾è°±çš„å…³ç³»åˆ—è¡¨åˆ°å•ä¸ªæ–‡ä»¶"""
        relations_file = self.get_graph_relations_file(graph_id)
        self._save_json(relations, relations_file)
        print(f"âœ… å·²ä¿å­˜å›¾è°± {graph_id} çš„ {len(relations)} ä¸ªå…³ç³»åˆ° {relations_file}")
    
    def load_graph_entities(self, graph_id: str) -> List[Dict[str, Any]]:
        """åŠ è½½å›¾è°±çš„æœ€ç»ˆå®ä½“åˆ—è¡¨ï¼ˆæ¶ˆæ­§åï¼‰"""
        entities_file = self.get_graph_entities_file(graph_id)
        if entities_file.exists():
            entities = self._load_json(entities_file)
            return entities if isinstance(entities, list) else []
        return []
    
    def load_graph_relations(self, graph_id: str) -> List[Dict[str, Any]]:
        """åŠ è½½å›¾è°±çš„å…³ç³»åˆ—è¡¨"""
        relations_file = self.get_graph_relations_file(graph_id)
        if relations_file.exists():
            relations = self._load_json(relations_file)
            return relations if isinstance(relations, list) else []
        return []
    
    def merge_and_disambiguate_entities(self, graph_id: str, new_entities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """åˆå¹¶æ–°å®ä½“ä¸ç°æœ‰å®ä½“å¹¶è¿›è¡Œæ¶ˆæ­§
        
        Args:
            graph_id: å›¾è°±ID
            new_entities: æ–°è¯†åˆ«çš„å®ä½“åˆ—è¡¨
            
        Returns:
            æ¶ˆæ­§åçš„æœ€ç»ˆå®ä½“åˆ—è¡¨
        """
        print(f"ğŸ”„ å¼€å§‹ä¸ºå›¾è°± {graph_id} è¿›è¡Œå®ä½“æ¶ˆæ­§...")
        
        # 1. åŠ è½½ç°æœ‰çš„æ¶ˆæ­§åå®ä½“
        existing_entities = self.load_graph_entities(graph_id)
        print(f"ğŸ“Š ç°æœ‰å®ä½“æ•°é‡: {len(existing_entities)}")
        print(f"ğŸ“Š æ–°å®ä½“æ•°é‡: {len(new_entities)}")
        
        if not existing_entities:
            # å¦‚æœæ²¡æœ‰ç°æœ‰å®ä½“ï¼Œç›´æ¥å¯¹æ–°å®ä½“è¿›è¡Œæ¶ˆæ­§
            print("ğŸ“ æ²¡æœ‰ç°æœ‰å®ä½“ï¼Œç›´æ¥å¯¹æ–°å®ä½“è¿›è¡Œæ¶ˆæ­§")
            return self._disambiguate_entity_list(new_entities)
        
        # 2. åˆå¹¶ç°æœ‰å®ä½“å’Œæ–°å®ä½“
        all_entities = existing_entities + new_entities
        print(f"ğŸ“Š åˆå¹¶åæ€»å®ä½“æ•°é‡: {len(all_entities)}")
        
        # 3. å¯¹åˆå¹¶åçš„å®ä½“åˆ—è¡¨è¿›è¡Œæ¶ˆæ­§
        disambiguated_entities = self._disambiguate_entity_list(all_entities)
        print(f"âœ… æ¶ˆæ­§å®Œæˆï¼Œæœ€ç»ˆå®ä½“æ•°é‡: {len(disambiguated_entities)}")
        
        # 4. ä¿å­˜æ¶ˆæ­§åçš„å®ä½“
        self.save_graph_entities(graph_id, disambiguated_entities)
        
        return disambiguated_entities
    
    def _disambiguate_entity_list(self, entities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å¯¹å®ä½“åˆ—è¡¨è¿›è¡Œæ¶ˆæ­§å¤„ç†
        
        Args:
            entities: å¾…æ¶ˆæ­§çš„å®ä½“åˆ—è¡¨
            
        Returns:
            æ¶ˆæ­§åçš„å®ä½“åˆ—è¡¨
        """
        if not entities:
            return []
        
        print(f"ğŸ” å¼€å§‹å¯¹ {len(entities)} ä¸ªå®ä½“è¿›è¡Œæ¶ˆæ­§...")
        
        # ä½¿ç”¨ç®€å•çš„åŸºäºåç§°å’Œç±»å‹çš„æ¶ˆæ­§ç­–ç•¥
        entity_groups = {}
        
        for entity in entities:
            entity_text = entity.get("entity_text", "").strip()
            entity_type = entity.get("entity_type", "").strip()
            
            if not entity_text or not entity_type:
                continue
            
            # åˆ›å»ºå®ä½“çš„å”¯ä¸€é”®ï¼ˆåŸºäºåç§°å’Œç±»å‹ï¼‰
            key = f"{entity_text.lower()}_{entity_type.lower()}"
            
            if key not in entity_groups:
                entity_groups[key] = {
                    "entity_text": entity_text,
                    "entity_type": entity_type,
                    "entity_description": entity.get("entity_description", ""),
                    "chunk_id": set(),
                    "category_path": set(),
                    "aliases": set()
                }
            
            # åˆå¹¶chunk_idå’Œcategory_path
            if "chunk_id" in entity:
                if isinstance(entity["chunk_id"], list):
                    entity_groups[key]["chunk_id"].update(entity["chunk_id"])
                else:
                    entity_groups[key]["chunk_id"].add(entity["chunk_id"])
            
            if "category_path" in entity:
                if isinstance(entity["category_path"], list):
                    entity_groups[key]["category_path"].update(entity["category_path"])
                else:
                    entity_groups[key]["category_path"].add(entity["category_path"])
            
            # æ”¶é›†åˆ«å
            if "aliases" in entity and isinstance(entity["aliases"], list):
                entity_groups[key]["aliases"].update(entity["aliases"])
            
            # æ›´æ–°æè¿°ï¼ˆé€‰æ‹©æ›´è¯¦ç»†çš„æè¿°ï¼‰
            current_desc = entity_groups[key]["entity_description"]
            new_desc = entity.get("entity_description", "")
            if len(new_desc) > len(current_desc):
                entity_groups[key]["entity_description"] = new_desc
        
        # è½¬æ¢ä¸ºæœ€ç»ˆæ ¼å¼
        final_entities = []
        for group in entity_groups.values():
            final_entity = {
                "entity_text": group["entity_text"],
                "entity_type": group["entity_type"],
                "entity_description": group["entity_description"],
                "chunk_id": sorted(list(group["chunk_id"])),
                "category_path": sorted(list(group["category_path"])),
                "aliases": sorted(list(group["aliases"])) if group["aliases"] else []
            }
            final_entities.append(final_entity)
        
        print(f"âœ… æ¶ˆæ­§å®Œæˆï¼Œä» {len(entities)} ä¸ªå®ä½“åˆå¹¶ä¸º {len(final_entities)} ä¸ªå”¯ä¸€å®ä½“")
        return final_entities
    
    def migrate_existing_data(self):
        """è¿ç§»ç°æœ‰æ•°æ®åˆ°æ–°çš„ä¼˜åŒ–ç»“æ„ ğŸ“¦"""
        print("ğŸš€ å¼€å§‹æ•°æ®è¿ç§»ï¼Œä¼˜åŒ–æ–‡ä»¶ç³»ç»Ÿç»“æ„...")
        
        # 1. è·å–æ‰€æœ‰å›¾è°±
        graphs = self.get_all_graphs()
        print(f"ğŸ“Š å‘ç° {len(graphs)} ä¸ªå›¾è°±éœ€è¦è¿ç§»")
        
        for graph in graphs:
            graph_id = graph["id"]
            print(f"\nğŸ”„ æ­£åœ¨è¿ç§»å›¾è°±: {graph_id}")
            
            try:
                # 2. è¿ç§»å®ä½“æ•°æ®
                self._migrate_graph_entities(graph_id)
                
                # 3. è¿ç§»å…³ç³»æ•°æ®
                self._migrate_graph_relations(graph_id)
                
                print(f"âœ… å›¾è°± {graph_id} è¿ç§»å®Œæˆ")
                
            except Exception as e:
                print(f"âŒ å›¾è°± {graph_id} è¿ç§»å¤±è´¥: {e}")
                continue
        
        print("\nğŸ‰ æ•°æ®è¿ç§»å®Œæˆï¼æ–°çš„æ–‡ä»¶ç³»ç»Ÿç»“æ„å·²ä¼˜åŒ–")
    
    def _migrate_graph_entities(self, graph_id: str):
        """è¿ç§»å›¾è°±å®ä½“æ•°æ®"""
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æ–°æ ¼å¼çš„å®ä½“æ–‡ä»¶
        new_entities_file = self.get_graph_entities_file(graph_id)
        if new_entities_file.exists():
            print(f"ğŸ“ å›¾è°± {graph_id} çš„å®ä½“æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡è¿ç§»")
            return
        
        # æŸ¥æ‰¾ç°æœ‰çš„æ¶ˆæ­§å®ä½“æ–‡ä»¶
        old_disambig_file = self.data_dir / "ner_pro_output" / graph_id / "all_entities_disambiguated.json"
        if not old_disambig_file.exists():
            # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
            old_disambig_file = self.data_dir / "ner_pro_output" / self._get_graph_name(graph_id) / "all_entities_disambiguated.json"
        
        if old_disambig_file.exists():
            print(f"ğŸ“‚ æ‰¾åˆ°ç°æœ‰æ¶ˆæ­§æ–‡ä»¶: {old_disambig_file}")
            entities = self._load_json(old_disambig_file)
            if entities and isinstance(entities, list):
                # æ ‡å‡†åŒ–å®ä½“æ ¼å¼
                standardized_entities = self._standardize_entity_format(entities)
                self.save_graph_entities(graph_id, standardized_entities)
                print(f"âœ… å·²è¿ç§» {len(standardized_entities)} ä¸ªå®ä½“")
            else:
                print(f"âš ï¸ æ¶ˆæ­§æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")
        else:
            print(f"ğŸ“ æœªæ‰¾åˆ°ç°æœ‰æ¶ˆæ­§æ–‡ä»¶ï¼Œåˆ›å»ºç©ºå®ä½“åˆ—è¡¨")
            self.save_graph_entities(graph_id, [])
    
    def _migrate_graph_relations(self, graph_id: str):
        """è¿ç§»å›¾è°±å…³ç³»æ•°æ®"""
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æ–°æ ¼å¼çš„å…³ç³»æ–‡ä»¶
        new_relations_file = self.get_graph_relations_file(graph_id)
        if new_relations_file.exists():
            print(f"ğŸ“ å›¾è°± {graph_id} çš„å…³ç³»æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡è¿ç§»")
            return
        
        # æŸ¥æ‰¾ç°æœ‰çš„å…³ç³»æ–‡ä»¶
        old_relations_dir = self.data_dir / "re_output" / graph_id
        if not old_relations_dir.exists():
            old_relations_dir = self.data_dir / "re_output" / self._get_graph_name(graph_id)
        
        relations = []
        if old_relations_dir.exists():
            print(f"ğŸ“‚ æŸ¥æ‰¾å…³ç³»æ–‡ä»¶: {old_relations_dir}")
            # æ”¶é›†æ‰€æœ‰å…³ç³»æ–‡ä»¶
            for relation_file in old_relations_dir.glob("*.json"):
                try:
                    relation_data = self._load_json(relation_file)
                    if isinstance(relation_data, list):
                        relations.extend(relation_data)
                    elif isinstance(relation_data, dict):
                        relations.append(relation_data)
                except Exception as e:
                    print(f"âš ï¸ è¯»å–å…³ç³»æ–‡ä»¶ {relation_file} å¤±è´¥: {e}")
        
        # ä¿å­˜å…³ç³»æ•°æ®
        self.save_graph_relations(graph_id, relations)
        print(f"âœ… å·²è¿ç§» {len(relations)} ä¸ªå…³ç³»")
    
    def _standardize_entity_format(self, entities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ ‡å‡†åŒ–å®ä½“æ ¼å¼"""
        standardized = []
        for entity in entities:
            standardized_entity = {
                "entity_text": entity.get("entity_text", ""),
                "entity_type": entity.get("entity_type", ""),
                "entity_description": entity.get("entity_description", ""),
                "chunk_id": entity.get("chunk_id", []) if isinstance(entity.get("chunk_id"), list) else [entity.get("chunk_id", "")],
                "category_path": entity.get("category_path", []) if isinstance(entity.get("category_path"), list) else [entity.get("category_path", "")],
                "aliases": entity.get("aliases", [])
            }
            standardized.append(standardized_entity)
        return standardized
      
      # å›¾è°±ç®¡ç†
    def _ensure_root_category(self):
        """ç¡®ä¿æ ¹åˆ†ç±»å­˜åœ¨"""
        root_category_path = self.categories_dir / "root.json"
        if not root_category_path.exists():
            root_category = {
                "id": "root",
                "name": "æ ¹ç›®å½•",
                "description": "çŸ¥è¯†å›¾è°±æ ¹åˆ†ç±»ç›®å½•",
                "parent_id": None,
                "level": 0,
                "path": "/",
                "children_ids": [],
                "graph_ids": [],
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat()
            }
            self._save_json(root_category, root_category_path)
    
    def create_category(self, name: str, description: str = "", parent_id: str = "root") -> Dict[str, Any]:
        """åˆ›å»ºæ–°åˆ†ç±»"""
        category_id = str(uuid.uuid4())
        
        # è·å–çˆ¶åˆ†ç±»ä¿¡æ¯
        parent_category = self.get_category(parent_id)
        if not parent_category:
            raise ValueError(f"çˆ¶åˆ†ç±» {parent_id} ä¸å­˜åœ¨")
        
        # è®¡ç®—åˆ†ç±»å±‚çº§å’Œè·¯å¾„
        level = parent_category["level"] + 1
        if level > 3:  # é™åˆ¶æœ€å¤§å±‚çº§ä¸º3çº§
            raise ValueError("åˆ†ç±»å±‚çº§ä¸èƒ½è¶…è¿‡3çº§")
        
        parent_path = parent_category["path"]
        path = f"{parent_path}{name}/" if parent_path != "/" else f"/{name}/"
        
        category_data = {
            "id": category_id,
            "name": name,
            "description": description,
            "parent_id": parent_id,
            "level": level,
            "path": path,
            "children_ids": [],
            "graph_ids": [],
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }
        
        # ä¿å­˜åˆ†ç±»
        self.save_category(category_id, category_data)
        
        # æ›´æ–°çˆ¶åˆ†ç±»çš„å­åˆ†ç±»åˆ—è¡¨
        parent_category["children_ids"].append(category_id)
        parent_category["updated_at"] = datetime.now().isoformat()
        self.save_category(parent_id, parent_category)
        
        return category_data
    
    def save_category(self, category_id: str, category_data: Dict[str, Any]):
        """ä¿å­˜åˆ†ç±»æ•°æ®"""
        file_path = self.categories_dir / f"{category_id}.json"
        self._save_json(category_data, file_path)
    
    def get_category(self, category_id: str) -> Optional[Dict[str, Any]]:
        """è·å–åˆ†ç±»ä¿¡æ¯"""
        file_path = self.categories_dir / f"{category_id}.json"
        if file_path.exists():
            data = self._load_json(file_path)
            return data if data else None
        return None
    
    def get_all_categories(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰åˆ†ç±»"""
        return self._get_all_files_data(self.categories_dir)
    
    def get_category_tree(self) -> Dict[str, Any]:
        """è·å–åˆ†ç±»æ ‘ç»“æ„"""
        # ç¡®ä¿æ ¹åˆ†ç±»å­˜åœ¨
        self._ensure_root_category()
        
        def build_tree(category_id: str) -> Dict[str, Any]:
            category = self.get_category(category_id)
            if not category:
                # å¦‚æœæ˜¯æ ¹åˆ†ç±»ä¸å­˜åœ¨ï¼ŒæŠ›å‡ºå¼‚å¸¸
                if category_id == "root":
                    raise Exception(f"æ ¹åˆ†ç±»ä¸å­˜åœ¨: {category_id}")
                # å…¶ä»–åˆ†ç±»ä¸å­˜åœ¨åˆ™è¿”å›None
                return None
            
            # æ„å»ºå­åˆ†ç±»æ ‘
            children = []
            for child_id in category.get("children_ids", []):
                child_tree = build_tree(child_id)
                if child_tree:
                    children.append(child_tree)
            
            return {
                **category,
                "children": children
            }
        
        return build_tree("root")
    
    def update_category(self, category_id: str, name: str, description: str = "") -> Optional[Dict[str, Any]]:
        """æ›´æ–°åˆ†ç±»ä¿¡æ¯"""
        category = self.get_category(category_id)
        if not category:
            return None
        
        # æ›´æ–°åŸºæœ¬ä¿¡æ¯
        category["name"] = name
        category["description"] = description
        category["updated_at"] = datetime.now().isoformat()
        
        # å¦‚æœåç§°æ”¹å˜ï¼Œéœ€è¦æ›´æ–°è·¯å¾„
        if category["name"] != name:
            old_path = category["path"]
            parent_category = self.get_category(category["parent_id"]) if category["parent_id"] else None
            if parent_category:
                parent_path = parent_category["path"]
                new_path = f"{parent_path}{name}/" if parent_path != "/" else f"/{name}/"
                category["path"] = new_path
                
                # é€’å½’æ›´æ–°æ‰€æœ‰å­åˆ†ç±»çš„è·¯å¾„
                self._update_children_paths(category_id, old_path, new_path)
        
        self.save_category(category_id, category)
        return category
    
    def _update_children_paths(self, category_id: str, old_path: str, new_path: str):
        """é€’å½’æ›´æ–°å­åˆ†ç±»è·¯å¾„"""
        category = self.get_category(category_id)
        if not category:
            return
        
        for child_id in category.get("children_ids", []):
            child = self.get_category(child_id)
            if child:
                child["path"] = child["path"].replace(old_path, new_path, 1)
                child["updated_at"] = datetime.now().isoformat()
                self.save_category(child_id, child)
                self._update_children_paths(child_id, old_path, new_path)
    
    def delete_category(self, category_id: str) -> bool:
        """åˆ é™¤åˆ†ç±»ï¼ˆé€’å½’åˆ é™¤å­åˆ†ç±»å’Œå›¾è°±ï¼‰"""
        if category_id == "root":
            raise ValueError("ä¸èƒ½åˆ é™¤æ ¹åˆ†ç±»")
        
        category = self.get_category(category_id)
        if not category:
            return False
        
        # é€’å½’åˆ é™¤æ‰€æœ‰å­åˆ†ç±»
        for child_id in category.get("children_ids", []):
            self.delete_category(child_id)
        
        # åˆ é™¤åˆ†ç±»ä¸‹çš„æ‰€æœ‰å›¾è°±ï¼ˆä¸åˆ é™¤å¯¹åº”åˆ†ç±»ï¼Œé¿å…å¾ªç¯è°ƒç”¨ï¼‰
        for graph_id in category.get("graph_ids", []):
            self.delete_graph(graph_id, delete_category=False)
        
        # ä»çˆ¶åˆ†ç±»ä¸­ç§»é™¤
        if category["parent_id"]:
            parent_category = self.get_category(category["parent_id"])
            if parent_category and category_id in parent_category.get("children_ids", []):
                parent_category["children_ids"].remove(category_id)
                parent_category["updated_at"] = datetime.now().isoformat()
                self.save_category(category["parent_id"], parent_category)
        
        # åˆ é™¤åˆ†ç±»æ–‡ä»¶
        file_path = self.categories_dir / f"{category_id}.json"
        if file_path.exists():
            file_path.unlink()
        
        return True
    
    def _find_top_level_category(self, category_id: str) -> Optional[str]:
        """æŸ¥æ‰¾æŒ‡å®šåˆ†ç±»çš„é¡¶çº§çˆ¶åˆ†ç±»ï¼ˆä¸€çº§åˆ†ç±»ï¼‰"""
        current_category = self.get_category(category_id)
        if not current_category:
            return None
        
        # å¦‚æœå·²ç»æ˜¯ä¸€çº§åˆ†ç±»ï¼Œç›´æ¥è¿”å›
        if current_category["level"] == 1:
            return category_id
        
        # é€’å½’æŸ¥æ‰¾çˆ¶åˆ†ç±»ï¼Œç›´åˆ°æ‰¾åˆ°ä¸€çº§åˆ†ç±»
        parent_id = current_category.get("parent_id")
        if parent_id and parent_id != "root":
            return self._find_top_level_category(parent_id)
        
        return None
    
    def _delete_category_only(self, category_id: str) -> bool:
        """ä»…åˆ é™¤åˆ†ç±»æœ¬èº«ï¼Œä¸é€’å½’åˆ é™¤å­åˆ†ç±»å’Œå›¾è°±ï¼ˆç”¨äºé¿å…å¾ªç¯è°ƒç”¨ï¼‰"""
        if category_id == "root":
            return False
        
        category = self.get_category(category_id)
        if not category:
            return False
        
        # ä»çˆ¶åˆ†ç±»ä¸­ç§»é™¤
        if category["parent_id"]:
            parent_category = self.get_category(category["parent_id"])
            if parent_category and category_id in parent_category.get("children_ids", []):
                parent_category["children_ids"].remove(category_id)
                parent_category["updated_at"] = datetime.now().isoformat()
                self.save_category(category["parent_id"], parent_category)
        
        # åˆ é™¤åˆ†ç±»æ–‡ä»¶
        file_path = self.categories_dir / f"{category_id}.json"
        if file_path.exists():
            file_path.unlink()
        
        return True
    
    def create_graph(self, name: str, description: str = "", domain: str = None, category_id: str = "root") -> Dict[str, Any]:
        """åˆ›å»ºæ–°çš„çŸ¥è¯†å›¾è°±"""
        graph_id = str(uuid.uuid4())
        
        # éªŒè¯åˆ†ç±»æ˜¯å¦å­˜åœ¨
        category = self.get_category(category_id)
        if not category:
            raise ValueError(f"åˆ†ç±» {category_id} ä¸å­˜åœ¨")
        
        graph_data = {
            "id": graph_id,
            "name": name,
            "description": description,
            "domain": domain or "é€šç”¨",
            "category_id": category_id,  # æ–°å¢ï¼šæ‰€å±åˆ†ç±»
            "category_path": category["path"],  # æ–°å¢ï¼šåˆ†ç±»è·¯å¾„
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat(),
            "entity_count": 0,
            "relation_count": 0,
            "status": "active"
        }
        
        # ä¿å­˜å›¾è°±
        file_path = self.graphs_dir / f"{graph_id}.json"
        self._save_json(graph_data, file_path)
        
        # æ›´æ–°åˆ†ç±»çš„å›¾è°±åˆ—è¡¨
        category["graph_ids"].append(graph_id)
        category["updated_at"] = datetime.now().isoformat()
        self.save_category(category_id, category)
        
        return graph_data
    
    def get_all_graphs(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰çŸ¥è¯†å›¾è°±"""
        graphs = self._get_all_files_data(self.graphs_dir)
        valid_graphs = []
        
        # æ›´æ–°å®ä½“å’Œå…³ç³»è®¡æ•°
        for graph in graphs:
            try:
                graph_id = graph["id"]
                entities = self.get_entities(graph_id)
                relations = self.get_relations(graph_id)
                entity_count = len(entities)
                relation_count = len(relations)
                
                # å®‰å…¨æ›´æ–°è®¡æ•°ï¼Œå¤„ç†ç¼ºå°‘å­—æ®µçš„æƒ…å†µ
                current_entity_count = graph.get("entity_count", 0)
                current_relation_count = graph.get("relation_count", 0)
                
                # æ›´æ–°è®¡æ•°
                graph["entity_count"] = entity_count
                graph["relation_count"] = relation_count
                
                # ç¡®ä¿æœ‰åˆ†ç±»ä¿¡æ¯ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
                if "category_id" not in graph:
                    graph["category_id"] = "root"
                    graph["category_path"] = "/"
                
                # è·å–åˆ†ç±»åç§°
                category = self.get_category(graph.get("category_id", "root"))
                graph["category_name"] = category["name"] if category else "æ ¹ç›®å½•"
                
                # åªæœ‰å½“è®¡æ•°å‘ç”Ÿå˜åŒ–æ—¶æ‰ä¿å­˜æ–‡ä»¶
                if current_entity_count != entity_count or current_relation_count != relation_count:
                    graph["updated_at"] = datetime.now().isoformat()
                    file_path = self.graphs_dir / f"{graph_id}.json"
                    self._save_json(graph, file_path)
                
                valid_graphs.append(graph)
            except Exception as e:
                print(f"âš ï¸ å¤„ç†å›¾è°± {graph.get('id', 'unknown')} æ—¶å‡ºé”™: {e}")
                # è·³è¿‡æœ‰é—®é¢˜çš„å›¾è°±ï¼Œç»§ç»­å¤„ç†å…¶ä»–å›¾è°±
                continue
        
        return sorted(valid_graphs, key=lambda x: x["created_at"], reverse=True)
    
    def get_graphs_by_category(self, category_id: str) -> List[Dict[str, Any]]:
        """è·å–æŒ‡å®šåˆ†ç±»ä¸‹çš„å›¾è°±"""
        all_graphs = self.get_all_graphs()
        
        if category_id == "root":
            # å¦‚æœæ˜¯æ ¹åˆ†ç±»ï¼Œè¿”å›æ‰€æœ‰å›¾è°±ï¼ˆåŒ…æ‹¬æ‰€æœ‰å­åˆ†ç±»çš„å›¾è°±ï¼‰
            return all_graphs
        else:
            # è·å–å½“å‰åˆ†ç±»ä¿¡æ¯
            current_category = self.get_category(category_id)
            if not current_category:
                return []
            
            # ğŸ†• æ ¹æ®åˆ†ç±»å±‚çº§å¤„ç†å›¾è°±æŸ¥æ‰¾é€»è¾‘
            if current_category["level"] == 1:
                # ä¸€çº§åˆ†ç±»ï¼šç›´æ¥è¿”å›è¯¥åˆ†ç±»ä¸‹çš„å›¾è°±
                return [graph for graph in all_graphs if graph.get("category_id") == category_id]
            else:
                # äºŒçº§åŠä»¥ä¸Šåˆ†ç±»ï¼šæŸ¥æ‰¾å…¶é¡¶çº§çˆ¶åˆ†ç±»ï¼ˆä¸€çº§åˆ†ç±»ï¼‰çš„å›¾è°±
                top_level_category_id = self._find_top_level_category(category_id)
                if top_level_category_id:
                    return [graph for graph in all_graphs if graph.get("category_id") == top_level_category_id]
                else:
                    return []
    
    def get_graph(self, graph_id: str) -> Optional[Dict[str, Any]]:
        """è·å–æŒ‡å®šçŸ¥è¯†å›¾è°±"""
        file_path = self.graphs_dir / f"{graph_id}.json"
        graph_data = self._load_json(file_path)
        
        if graph_data:
            # æ›´æ–°å®ä½“å’Œå…³ç³»è®¡æ•°
            entities = self.get_entities(graph_id)
            relations = self.get_relations(graph_id)
            entity_count = len(entities)
            relation_count = len(relations)
            
            # å®‰å…¨æ›´æ–°è®¡æ•°ï¼Œå¤„ç†ç¼ºå°‘å­—æ®µçš„æƒ…å†µ
            current_entity_count = graph_data.get("entity_count", 0)
            current_relation_count = graph_data.get("relation_count", 0)
            
            # æ›´æ–°è®¡æ•°
            graph_data["entity_count"] = entity_count
            graph_data["relation_count"] = relation_count
            
            # åªæœ‰å½“è®¡æ•°å‘ç”Ÿå˜åŒ–æ—¶æ‰ä¿å­˜æ–‡ä»¶
            if current_entity_count != entity_count or current_relation_count != relation_count:
                graph_data["updated_at"] = datetime.now().isoformat()
                self._save_json(graph_data, file_path)
        
        return graph_data if graph_data else None
    
    def update_graph(self, graph_id: str, name: str, description: str = "", domain: str = None) -> Optional[Dict[str, Any]]:
        """æ›´æ–°çŸ¥è¯†å›¾è°±"""
        file_path = self.graphs_dir / f"{graph_id}.json"
        graph_data = self._load_json(file_path)
        
        if graph_data:
            graph_data["name"] = name
            graph_data["description"] = description
            if domain is not None:
                graph_data["domain"] = domain
            graph_data["updated_at"] = datetime.now().isoformat()
            self._save_json(graph_data, file_path)
            return graph_data
        
        return None
    
    def delete_graph(self, graph_id: str, delete_category: bool = True) -> bool:
        """åˆ é™¤çŸ¥è¯†å›¾è°±åŠå…¶ç›¸å…³æ•°æ®
        
        Args:
            graph_id: å›¾è°±ID
            delete_category: æ˜¯å¦åŒæ—¶åˆ é™¤å¯¹åº”çš„åˆ†ç±»ï¼ˆé»˜è®¤Trueï¼‰
        """
        file_path = self.graphs_dir / f"{graph_id}.json"
        
        if file_path.exists():
            # è·å–å›¾è°±ä¿¡æ¯ä»¥ä¾¿ä»åˆ†ç±»ä¸­ç§»é™¤
            graph_data = self._load_json(file_path)
            category_id = graph_data.get("category_id", "root")
            
            # ä»åˆ†ç±»ä¸­ç§»é™¤å›¾è°±
            category = self.get_category(category_id)
            if category and graph_id in category.get("graph_ids", []):
                category["graph_ids"].remove(graph_id)
                category["updated_at"] = datetime.now().isoformat()
                self.save_category(category_id, category)
                
                # å¦‚æœåˆ†ç±»ä¸‹æ²¡æœ‰å…¶ä»–å›¾è°±ä¸”ä¸æ˜¯æ ¹åˆ†ç±»ï¼Œåˆ™åˆ é™¤è¯¥åˆ†ç±»
                if (delete_category and 
                    category_id != "root" and 
                    len(category.get("graph_ids", [])) == 0 and 
                    len(category.get("children_ids", [])) == 0):
                    self._delete_category_only(category_id)
            
            # åˆ é™¤å›¾è°±æ–‡ä»¶
            file_path.unlink()
            
            # åˆ é™¤ç›¸å…³å®ä½“
            entities = self.get_entities(graph_id)
            for entity in entities:
                self.delete_entity(entity["id"])
            
            # åˆ é™¤ç›¸å…³å…³ç³»
            relations = self.get_relations(graph_id)
            for relation in relations:
                self.delete_relation(relation["id"])
            
            return True
        
        return False
    
    # å®ä½“ç®¡ç†
    def create_entity(self, name: str, entity_type: str, description: str = "", graph_id: str = "") -> Dict[str, Any]:
        """åˆ›å»ºæ–°å®ä½“"""
        entity_id = str(uuid.uuid4())
        
        # è·å–å›¾è°±çš„åˆ†ç±»è·¯å¾„
        category_path = "/root"
        if graph_id:
            graph = self.get_graph(graph_id)
            if graph and graph.get("category_id"):
                category = self.get_category(graph["category_id"])
                if category:
                    category_path = category.get("path", "/root")
        
        entity_data = {
            "id": entity_id,
            "name": name,
            "type": entity_type,
            "description": description,
            "graph_id": graph_id,
            "category_path": category_path,  # æ·»åŠ åˆ†ç±»è·¯å¾„å±æ€§
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat(),
            "frequency": 1,
            "aliases": []
        }
        
        # ä½¿ç”¨æ–°çš„å›¾è°±ç‰¹å®šå­˜å‚¨é€»è¾‘
        self.save_entity(entity_id, entity_data, graph_id)
        return entity_data
    
    def get_entities(self, graph_id: str = None) -> List[Dict[str, Any]]:
        """è·å–å®ä½“åˆ—è¡¨"""
        try:
            if graph_id:
                # ä»å›¾è°±ç‰¹å®šç›®å½•è¯»å–
                try:
                    graph_entities_dir = self._get_graph_entities_dir(graph_id)
                except Exception as e:
                    print(f"âš ï¸ è·å–å›¾è°±å®ä½“ç›®å½•å¤±è´¥ (graph_id: {graph_id}): {e}")
                    return []
                
                entities = []
                
                # è¯»å– ner_pro_output ç›®å½•ä¸­çš„å®ä½“æ–‡ä»¶
                for json_file in graph_entities_dir.glob("*.json"):
                    # ä¼˜å…ˆè¯»å–æ¶ˆæ­§åçš„å®ä½“æ–‡ä»¶
                    if json_file.name == "all_entities_disambiguated.json":
                        try:
                            entity_data = self._load_json(json_file)
                            if isinstance(entity_data, list):
                                # æ¶ˆæ­§åçš„å®ä½“æ•°æ®å·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼Œç›´æ¥è½¬æ¢
                                for entity in entity_data:
                                    try:
                                        # ä½¿ç”¨entity_textå’Œgraph_idç”Ÿæˆç¨³å®šçš„ID
                                        entity_text = entity.get("entity_text", entity.get("name", ""))
                                        stable_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, f"{graph_id}:{entity_text}"))
                                        entities.append({
                                            "id": entity.get("entity_id", stable_id),
                                            "name": entity_text,
                                            "type": entity.get("entity_type", entity.get("type", "")),
                                            "description": entity.get("entity_description", entity.get("description", "")),
                                            "graph_id": graph_id,
                                            "frequency": len(entity.get("chunk_id", [])) if entity.get("chunk_id") else 1,
                                            "created_at": datetime.now().isoformat(),
                                            "updated_at": datetime.now().isoformat(),
                                            "aliases": entity.get("aliases", [])
                                        })
                                    except Exception as e:
                                        print(f"âš ï¸ å¤„ç†æ¶ˆæ­§å®ä½“æ•°æ®æ—¶å‡ºé”™: {e}")
                                        continue
                        except Exception as e:
                            print(f"âš ï¸ è¯»å–æ¶ˆæ­§å®ä½“æ–‡ä»¶ {json_file} æ—¶å‡ºé”™: {e}")
                            continue
                    else:
                        # è¯»å–å…¶ä»–å®ä½“æ–‡ä»¶ï¼ˆåŸå§‹NERè¾“å‡ºç­‰ï¼‰
                        try:
                            entity_data = self._load_json(json_file)
                            print(entity_data)
                            if isinstance(entity_data, list):
                                # è½¬æ¢ NER è¾“å‡ºæ ¼å¼ä¸ºæ ‡å‡†å®ä½“æ ¼å¼
                                for entity in entity_data:
                                    try:
                                        entities.append({
                                            "id": entity.get("entity_id", str(uuid.uuid4())),
                                            "name": entity.get("entity_text", entity.get("name", "")),
                                            "type": entity.get("entity_type", entity.get("type", "")),
                                            "description": entity.get("entity_description", entity.get("description", "")),
                                            "graph_id": graph_id,
                                            "frequency": len(entity.get("chunk_id", [])) if entity.get("chunk_id") else 1,
                                            "created_at": datetime.now().isoformat(),
                                            "updated_at": datetime.now().isoformat(),
                                            "aliases": entity.get("aliases", [])
                                        })
                                    except Exception as e:
                                        print(f"âš ï¸ å¤„ç†å®ä½“æ•°æ®æ—¶å‡ºé”™: {e}")
                                        continue
                            elif isinstance(entity_data, dict):
                                # å•ä¸ªå®ä½“æ–‡ä»¶
                                entities.append(entity_data)
                        except Exception as e:
                            print(f"âš ï¸ è¯»å–å®ä½“æ–‡ä»¶ {json_file} æ—¶å‡ºé”™: {e}")
                            continue
                
                # ç„¶åè¯»å–å…¶ä»–å•ç‹¬çš„å®ä½“æ–‡ä»¶ï¼ˆå‘åå…¼å®¹ï¼‰
                try:
                    other_entities = self._get_all_files_data(graph_entities_dir)
                    entities.extend(other_entities)
                except Exception as e:
                    print(f"âš ï¸ è¯»å–å…¶ä»–å®ä½“æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                
                # åŒæ—¶ä¹Ÿä»å…¨å±€ç›®å½•ä¸­æŸ¥æ‰¾è¯¥å›¾è°±çš„å®ä½“ï¼ˆå‘åå…¼å®¹ï¼‰
                # try:
                #     global_entities = self._get_all_files_data(self.entities_dir)
                #     global_entities = [e for e in global_entities if e.get("graph_id") == graph_id]
                #     entities.extend(global_entities)
                # except Exception as e:
                #     print(f"âš ï¸ è¯»å–å…¨å±€å®ä½“æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                    
            else:
                # è·å–æ‰€æœ‰å®ä½“ï¼šå…¨å±€ç›®å½• + æ‰€æœ‰å›¾è°±ç›®å½•
                entities = []
                try:
                    entities = self._get_all_files_data(self.entities_dir)
                except Exception as e:
                    print(f"âš ï¸ è¯»å–å…¨å±€å®ä½“ç›®å½•æ—¶å‡ºé”™: {e}")
                
                # éå†æ‰€æœ‰å›¾è°±å­ç›®å½•
                try:
                    for graph_dir in self.entities_dir.iterdir():
                        if graph_dir.is_dir():
                            try:
                                # è¯»å–æ¶ˆæ­§æ–‡ä»¶
                                disambig_file = graph_dir / "all_entities_disambiguated.json"
                                if disambig_file.exists():
                                    disambig_data = self._load_json(disambig_file)
                                    if isinstance(disambig_data, list):
                                        for entity in disambig_data:
                                            try:
                                                entities.append({
                                                    "id": entity.get("entity_id", str(uuid.uuid4())),
                                                    "name": entity.get("entity_text", entity.get("name", "")),
                                                    "type": entity.get("entity_type", entity.get("type", "")),
                                                    "description": entity.get("entity_description", entity.get("description", "")),
                                                    "graph_id": graph_dir.name,
                                                    "frequency": len(entity.get("chunk_id", [])),
                                                    "created_at": datetime.now().isoformat(),
                                                    "updated_at": datetime.now().isoformat(),
                                                    "aliases": entity.get("aliases", [])
                                                })
                                            except Exception as e:
                                                print(f"âš ï¸ å¤„ç†æ¶ˆæ­§å®ä½“æ•°æ®æ—¶å‡ºé”™: {e}")
                                                continue
                                # è¯»å–å…¶ä»–å•ç‹¬æ–‡ä»¶
                                graph_entities = self._get_all_files_data(graph_dir)
                                entities.extend(graph_entities)
                            except Exception as e:
                                print(f"âš ï¸ å¤„ç†å›¾è°±ç›®å½• {graph_dir} æ—¶å‡ºé”™: {e}")
                                continue
                except Exception as e:
                    print(f"âš ï¸ éå†å®ä½“ç›®å½•æ—¶å‡ºé”™: {e}")
            
            # è¿‡æ»¤æ‰éå­—å…¸å¯¹è±¡ï¼Œç¡®ä¿æ’åºå®‰å…¨
            valid_entities = [e for e in entities if isinstance(e, dict)]
            return sorted(valid_entities, key=lambda x: x.get("created_at", ""), reverse=True)
        except Exception as e:
            print(f"âš ï¸ è·å–å®ä½“æ•°æ®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return []
    
    def get_entity(self, entity_id: str, graph_id: str = None) -> Optional[Dict[str, Any]]:
        """è·å–æŒ‡å®šå®ä½“"""
        if graph_id:
            # å…ˆä»å›¾è°±ç‰¹å®šç›®å½•æŸ¥æ‰¾
            graph_entities_dir = self._get_graph_entities_dir(graph_id)
            file_path = graph_entities_dir / f"{entity_id}.json"
            if file_path.exists():
                return self._load_json(file_path)
        
        # ä»å…¨å±€ç›®å½•æŸ¥æ‰¾ï¼ˆå‘åå…¼å®¹ï¼‰
        file_path = self.entities_dir / f"{entity_id}.json"
        if file_path.exists():
            return self._load_json(file_path)
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šgraph_idï¼Œéå†æ‰€æœ‰å›¾è°±ç›®å½•æŸ¥æ‰¾
        if not graph_id:
            for graph_dir in self.entities_dir.iterdir():
                if graph_dir.is_dir():
                    file_path = graph_dir / f"{entity_id}.json"
                    if file_path.exists():
                        return self._load_json(file_path)
        
        return None
    
    def update_entity(self, entity_id: str, name: str, entity_type: str, description: str = "") -> Optional[Dict[str, Any]]:
        """æ›´æ–°å®ä½“"""
        # é¦–å…ˆå°è¯•ä»å…¨å±€ç›®å½•æŸ¥æ‰¾
        file_path = self.entities_dir / f"{entity_id}.json"
        entity_data = self._load_json(file_path) if file_path.exists() else None
        
        # å¦‚æœå…¨å±€ç›®å½•æ²¡æ‰¾åˆ°ï¼Œéå†å›¾è°±å­ç›®å½•æŸ¥æ‰¾
        if not entity_data:
            for graph_dir in self.entities_dir.iterdir():
                if graph_dir.is_dir():
                    graph_file_path = graph_dir / f"{entity_id}.json"
                    if graph_file_path.exists():
                        entity_data = self._load_json(graph_file_path)
                        file_path = graph_file_path
                        break
        
        if entity_data:
            entity_data["name"] = name
            entity_data["type"] = entity_type
            entity_data["description"] = description
            entity_data["updated_at"] = datetime.now().isoformat()
            self._save_json(entity_data, file_path)
            return entity_data
        
        return None
    
    def delete_entity(self, entity_id: str) -> bool:
        """åˆ é™¤å®ä½“"""
        print(f"ğŸ—‘ï¸ å¼€å§‹åˆ é™¤å®ä½“: {entity_id}")
        found = False
        deleted_entity_name = None
        
        # åœ¨åˆ é™¤å®ä½“ä¹‹å‰ï¼Œå…ˆè·å–å®ä½“åç§°ç”¨äºåˆ é™¤ç›¸å…³å…³ç³»
        try:
            ner_pro_output_dir = self.data_dir / "ner_pro_output"
            if ner_pro_output_dir.exists():
                for graph_dir in ner_pro_output_dir.iterdir():
                    if graph_dir.is_dir():
                        graph_id = graph_dir.name
                        disambig_file = graph_dir / "all_entities_disambiguated.json"
                        if disambig_file.exists():
                            try:
                                entities = self._load_json(disambig_file)
                                if isinstance(entities, list):
                                    for entity in entities:
                                        entity_text = entity.get("entity_text", entity.get("name", ""))
                                        stable_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, f"{graph_id}:{entity_text}"))
                                        if stable_id == entity_id:
                                            deleted_entity_name = entity_text
                                            print(f"ğŸ“ æ‰¾åˆ°è¦åˆ é™¤çš„å®ä½“åç§°: {deleted_entity_name}")
                                            break
                            except Exception as e:
                                continue
                        if deleted_entity_name:
                            break
        except Exception as e:
            print(f"âš ï¸ è·å–å®ä½“åç§°æ—¶å‡ºé”™: {e}")
        
        # é¦–å…ˆå°è¯•ä»æ—§çš„å•æ–‡ä»¶å­˜å‚¨æ ¼å¼åˆ é™¤ï¼ˆå‘åå…¼å®¹ï¼‰
        file_path = self.entities_dir / f"{entity_id}.json"
        if file_path.exists():
            file_path.unlink()
            found = True
        
        # éå†å›¾è°±å­ç›®å½•æŸ¥æ‰¾å¹¶åˆ é™¤ï¼ˆå‘åå…¼å®¹ï¼‰
        for graph_dir in self.entities_dir.iterdir():
            if graph_dir.is_dir():
                graph_file_path = graph_dir / f"{entity_id}.json"
                if graph_file_path.exists():
                    graph_file_path.unlink()
                    found = True
        
        # ä»æ¶ˆæ­§åçš„å®ä½“æ–‡ä»¶ä¸­åˆ é™¤ï¼ˆæ–°çš„å­˜å‚¨æ ¼å¼ï¼‰
        try:
            # éå†æ‰€æœ‰å›¾è°±çš„æ¶ˆæ­§å®ä½“æ–‡ä»¶
            ner_pro_output_dir = self.data_dir / "ner_pro_output"
            if ner_pro_output_dir.exists():
                for graph_dir in ner_pro_output_dir.iterdir():
                    if graph_dir.is_dir():
                        disambig_file = graph_dir / "all_entities_disambiguated.json"
                        if disambig_file.exists():
                            try:
                                entities = self._load_json(disambig_file)
                                if isinstance(entities, list):
                                    # æŸ¥æ‰¾å¹¶åˆ é™¤æŒ‡å®šå®ä½“ - é€šè¿‡ç¨³å®šIDåŒ¹é…
                                    original_count = len(entities)
                                    graph_id = graph_dir.name  # è·å–å›¾è°±ID
                                    filtered_entities = []
                                    
                                    for entity in entities:
                                        # ç”Ÿæˆç¨³å®šIDç”¨äºåŒ¹é…
                                        entity_text = entity.get("entity_text", entity.get("name", ""))
                                        stable_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, f"{graph_id}:{entity_text}"))
                                        
                                        # å¦‚æœä¸åŒ¹é…è¦åˆ é™¤çš„IDï¼Œåˆ™ä¿ç•™
                                        if stable_id != entity_id and entity.get("entity_id") != entity_id and entity.get("id") != entity_id:
                                            filtered_entities.append(entity)
                                    
                                    if len(filtered_entities) < original_count:
                                        # æ‰¾åˆ°å¹¶åˆ é™¤äº†å®ä½“ï¼Œé‡æ–°ä¿å­˜æ–‡ä»¶
                                        self._save_json(filtered_entities, disambig_file)
                                        found = True
                                        print(f"âœ… ä»æ¶ˆæ­§æ–‡ä»¶ä¸­åˆ é™¤å®ä½“ {entity_id} (å›¾è°±: {graph_id})")
                            except Exception as e:
                                print(f"âš ï¸ å¤„ç†æ¶ˆæ­§æ–‡ä»¶ {disambig_file} æ—¶å‡ºé”™: {e}")
                                continue
        except Exception as e:
            print(f"âš ï¸ åˆ é™¤æ¶ˆæ­§å®ä½“æ—¶å‡ºé”™: {e}")
        
        if found:
            # åˆ é™¤ç›¸å…³å…³ç³» - ä½¿ç”¨é¢„å…ˆè·å–çš„å®ä½“åç§°
            try:
                if deleted_entity_name:
                    print(f"ğŸ”— å¼€å§‹åˆ é™¤ä¸å®ä½“ '{deleted_entity_name}' ç›¸å…³çš„å…³ç³»")
                    # åˆ é™¤all_relations.jsonä¸­çš„ç›¸å…³å…³ç³»
                    ner_pro_output_dir = self.data_dir / "ner_pro_output"
                    if ner_pro_output_dir.exists():
                        for graph_dir in ner_pro_output_dir.iterdir():
                            if graph_dir.is_dir():
                                relations_dir = self.data_dir / "re_output" / graph_dir.name
                                if relations_dir.exists():
                                    relations_file = relations_dir / "all_relations.json"
                                    if relations_file.exists():
                                        try:
                                            relations = self._load_json(relations_file)
                                            if isinstance(relations, list):
                                                original_count = len(relations)
                                                # è¿‡æ»¤æ‰åŒ…å«è¢«åˆ é™¤å®ä½“çš„å…³ç³»
                                                filtered_relations = [
                                                    r for r in relations 
                                                    if r.get("head") != deleted_entity_name and r.get("tail") != deleted_entity_name
                                                ]
                                                if len(filtered_relations) < original_count:
                                                    self._save_json(filtered_relations, relations_file)
                                                    removed_count = original_count - len(filtered_relations)
                                                    print(f"âœ… åˆ é™¤äº† {removed_count} ä¸ªç›¸å…³å…³ç³»")
                                        except Exception as e:
                                            print(f"âš ï¸ å¤„ç†å…³ç³»æ–‡ä»¶ {relations_file} æ—¶å‡ºé”™: {e}")
                else:
                    print(f"âš ï¸ æœªæ‰¾åˆ°å®ä½“ {entity_id} å¯¹åº”çš„åç§°ï¼Œæ— æ³•åˆ é™¤ç›¸å…³å…³ç³»")
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤ç›¸å…³å…³ç³»æ—¶å‡ºé”™: {e}")
            return True
        
        return False
    
    # å…³ç³»ç®¡ç†
    def create_relation(self, source_entity_id: str, target_entity_id: str, 
                       relation_type: str, confidence: float = 1.0, 
                       description: str = "", graph_id: str = "") -> Dict[str, Any]:
        """åˆ›å»ºæ–°å…³ç³»"""
        relation_id = str(uuid.uuid4())
        relation_data = {
            "id": relation_id,
            "source_entity_id": source_entity_id,
            "target_entity_id": target_entity_id,
            "relation_type": relation_type,
            "confidence": confidence,
            "description": description,
            "graph_id": graph_id,
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }
        
        # ä½¿ç”¨æ–°çš„å›¾è°±ç‰¹å®šå­˜å‚¨é€»è¾‘
        self.save_relation(relation_id, relation_data, graph_id)
        return relation_data
    
    def get_relations(self, graph_id: str = None) -> List[Dict[str, Any]]:
        """è·å–å…³ç³»åˆ—è¡¨"""
        try:
            if graph_id:
                # ä»å›¾è°±ç‰¹å®šç›®å½•è¯»å–
                try:
                    graph_relations_dir = self._get_graph_relations_dir(graph_id)
                except Exception as e:
                    print(f"âš ï¸ è·å–å›¾è°±å…³ç³»ç›®å½•å¤±è´¥ (graph_id: {graph_id}): {e}")
                    return []
                
                relations = []
                
                # è¯»å– re_output ç›®å½•ä¸­çš„å…³ç³»æ–‡ä»¶
                for json_file in graph_relations_dir.glob("*.json"):
                    if json_file.name != "all_relations_disambiguated.json":  # è·³è¿‡æ¶ˆæ­§æ–‡ä»¶
                        try:
                            relation_data = self._load_json(json_file)
                            if isinstance(relation_data, list):
                                # è½¬æ¢ RE è¾“å‡ºæ ¼å¼ä¸ºæ ‡å‡†å…³ç³»æ ¼å¼
                                for relation in relation_data:
                                    try:
                                        # ç”Ÿæˆç¨³å®šçš„å…³ç³»IDï¼ŒåŸºäºå›¾è°±IDã€å¤´å®ä½“ã€å…³ç³»ç±»å‹ã€å°¾å®ä½“
                                        head = relation.get("head", "")
                                        relation_type = relation.get("relation", relation.get("type", ""))
                                        tail = relation.get("tail", "")
                                        stable_relation_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, f"{graph_id}:{head}:{relation_type}:{tail}"))
                                        
                                        relations.append({
                                            "id": stable_relation_id,
                                            "relation_type": relation_type,
                                            "description": relation.get("relation_description", relation.get("description", "")),
                                            "source_entity_id": head,
                                            "target_entity_id": tail,
                                            "graph_id": graph_id,
                                            "confidence": 1.0,
                                            "frequency": len(relation.get("source_chunk_id", [])) if relation.get("source_chunk_id") else 1,
                                            "created_at": datetime.now().isoformat(),
                                            "updated_at": datetime.now().isoformat()
                                        })
                                    except Exception as e:
                                        print(f"âš ï¸ å¤„ç†å…³ç³»æ•°æ®æ—¶å‡ºé”™: {e}")
                                        continue
                            elif isinstance(relation_data, dict):
                                # å•ä¸ªå…³ç³»æ–‡ä»¶
                                relations.append(relation_data)
                        except Exception as e:
                            print(f"âš ï¸ è¯»å–å…³ç³»æ–‡ä»¶ {json_file} æ—¶å‡ºé”™: {e}")
                            continue
                
                # ç„¶åè¯»å–å…¶ä»–å•ç‹¬çš„å…³ç³»æ–‡ä»¶ï¼ˆå‘åå…¼å®¹ï¼‰
                try:
                    other_relations = self._get_all_files_data(graph_relations_dir)
                    relations.extend(other_relations)
                except Exception as e:
                    print(f"âš ï¸ è¯»å–å…¶ä»–å…³ç³»æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                
                # åŒæ—¶ä¹Ÿä»å…¨å±€ç›®å½•ä¸­æŸ¥æ‰¾è¯¥å›¾è°±çš„å…³ç³»ï¼ˆå‘åå…¼å®¹ï¼‰
                try:
                    global_relations = self._get_all_files_data(self.relations_dir)
                    global_relations = [r for r in global_relations if r.get("graph_id") == graph_id]
                    relations.extend(global_relations)
                except Exception as e:
                    print(f"âš ï¸ è¯»å–å…¨å±€å…³ç³»æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                    
            else:
                # è·å–æ‰€æœ‰å…³ç³»ï¼šå…¨å±€ç›®å½• + æ‰€æœ‰å›¾è°±ç›®å½•
                relations = []
                try:
                    relations = self._get_all_files_data(self.relations_dir)
                except Exception as e:
                    print(f"âš ï¸ è¯»å–å…¨å±€å…³ç³»ç›®å½•æ—¶å‡ºé”™: {e}")
                
                # éå†æ‰€æœ‰å›¾è°±å­ç›®å½•
                try:
                    for graph_dir in self.relations_dir.iterdir():
                        if graph_dir.is_dir():
                            try:
                                # è¯»å–æ¶ˆæ­§æ–‡ä»¶
                                disambig_file = graph_dir / "all_relations_disambiguated.json"
                                if disambig_file.exists():
                                    disambig_data = self._load_json(disambig_file)
                                    if isinstance(disambig_data, list):
                                        for relation in disambig_data:
                                            try:
                                                relations.append({
                                                    "id": relation.get("relation_id", str(uuid.uuid4())),
                                                    "relation_type": relation.get("relation_type", relation.get("type", "")),
                                                    "description": relation.get("relation_description", relation.get("description", "")),
                                                    "source_entity_id": relation.get("source_entity_id", ""),
                                                    "target_entity_id": relation.get("target_entity_id", ""),
                                                    "graph_id": graph_dir.name,
                                                    "confidence": 1.0,
                                                    "frequency": len(relation.get("chunk_id", [])),
                                                    "created_at": datetime.now().isoformat(),
                                                    "updated_at": datetime.now().isoformat()
                                                })
                                            except Exception as e:
                                                print(f"âš ï¸ å¤„ç†æ¶ˆæ­§å…³ç³»æ•°æ®æ—¶å‡ºé”™: {e}")
                                                continue
                                # è¯»å–å…¶ä»–å•ç‹¬æ–‡ä»¶
                                graph_relations = self._get_all_files_data(graph_dir)
                                relations.extend(graph_relations)
                            except Exception as e:
                                print(f"âš ï¸ å¤„ç†å…³ç³»ç›®å½• {graph_dir} æ—¶å‡ºé”™: {e}")
                                continue
                except Exception as e:
                    print(f"âš ï¸ éå†å…³ç³»ç›®å½•æ—¶å‡ºé”™: {e}")
            
            # è¿‡æ»¤æ‰éå­—å…¸å¯¹è±¡ï¼Œç¡®ä¿å¤„ç†å®‰å…¨
            valid_relations = [r for r in relations if isinstance(r, dict)]
            
            # æ·»åŠ å®ä½“åç§°ä¿¡æ¯
            try:
                for relation in valid_relations:
                    try:
                        # å¦‚æœsource_entity_idå’Œtarget_entity_idå­˜å‚¨çš„æ˜¯å®ä½“åç§°ï¼Œéœ€è¦å…ˆæ‰¾åˆ°å¯¹åº”çš„å®ä½“ID
                        source_entity_name = relation["source_entity_id"]
                        target_entity_name = relation["target_entity_id"]
                        
                        # ä»å½“å‰å›¾è°±çš„å®ä½“ä¸­æŸ¥æ‰¾åŒ¹é…çš„å®ä½“
                        entities = self.get_entities(graph_id) if graph_id else self.get_entities()
                        
                        source_entity = None
                        target_entity = None
                        
                        for entity in entities:
                            if entity["name"] == source_entity_name:
                                source_entity = entity
                            if entity["name"] == target_entity_name:
                                target_entity = entity
                        
                        relation["source_entity_name"] = source_entity["name"] if source_entity else source_entity_name
                        relation["target_entity_name"] = target_entity["name"] if target_entity else target_entity_name
                    except Exception as e:
                        print(f"âš ï¸ å¤„ç†å…³ç³»å®ä½“åç§°æ—¶å‡ºé”™: {e}")
                        # è®¾ç½®é»˜è®¤å€¼
                        relation["source_entity_name"] = relation.get("source_entity_id", "æœªçŸ¥")
                        relation["target_entity_name"] = relation.get("target_entity_id", "æœªçŸ¥")
                        continue
            except Exception as e:
                print(f"âš ï¸ æ·»åŠ å®ä½“åç§°ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            
            return sorted(valid_relations, key=lambda x: x.get("created_at", ""), reverse=True)
        except Exception as e:
            print(f"âš ï¸ è·å–å…³ç³»æ•°æ®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return []
    
    def delete_relation(self, relation_id: str) -> bool:
        """åˆ é™¤å…³ç³»"""
        print(f"ğŸ—‘ï¸ å¼€å§‹åˆ é™¤å…³ç³»: {relation_id}")
        found = False
        
        try:
            # é¦–å…ˆå°è¯•ä»å…¨å±€ç›®å½•åˆ é™¤å•ç‹¬çš„å…³ç³»æ–‡ä»¶ï¼ˆå‘åå…¼å®¹ï¼‰
            file_path = self.relations_dir / f"{relation_id}.json"
            if file_path.exists():
                file_path.unlink()
                found = True
                print(f"âœ… ä»å…¨å±€ç›®å½•åˆ é™¤å…³ç³»æ–‡ä»¶: {relation_id}.json")
            
            # éå†å›¾è°±å­ç›®å½•æŸ¥æ‰¾å¹¶åˆ é™¤å•ç‹¬çš„å…³ç³»æ–‡ä»¶ï¼ˆå‘åå…¼å®¹ï¼‰
            for graph_dir in self.relations_dir.iterdir():
                if graph_dir.is_dir():
                    graph_file_path = graph_dir / f"{relation_id}.json"
                    if graph_file_path.exists():
                        graph_file_path.unlink()
                        found = True
                        print(f"âœ… ä»å›¾è°±ç›®å½•åˆ é™¤å…³ç³»æ–‡ä»¶: {graph_dir.name}/{relation_id}.json")
            
            # ä»all_relations.jsonæ–‡ä»¶ä¸­åˆ é™¤å…³ç³»
            re_output_dir = self.data_dir / "re_output"
            if re_output_dir.exists():
                for graph_dir in re_output_dir.iterdir():
                    if graph_dir.is_dir():
                        graph_id = graph_dir.name
                        relations_file = graph_dir / "all_relations.json"
                        if relations_file.exists():
                            try:
                                relations = self._load_json(relations_file)
                                if isinstance(relations, list):
                                    original_count = len(relations)
                                    # è¿‡æ»¤æ‰è¦åˆ é™¤çš„å…³ç³»ï¼Œä½¿ç”¨ç¨³å®šIDåŒ¹é…
                                    filtered_relations = []
                                    for relation in relations:
                                        head = relation.get("head", "")
                                        relation_type = relation.get("relation", "")
                                        tail = relation.get("tail", "")
                                        stable_relation_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, f"{graph_id}:{head}:{relation_type}:{tail}"))
                                        
                                        if stable_relation_id != relation_id:
                                            filtered_relations.append(relation)
                                    
                                    if len(filtered_relations) < original_count:
                                        self._save_json(filtered_relations, relations_file)
                                        removed_count = original_count - len(filtered_relations)
                                        found = True
                                        print(f"âœ… ä» {relations_file} åˆ é™¤äº† {removed_count} ä¸ªå…³ç³»")
                            except Exception as e:
                                print(f"âš ï¸ å¤„ç†å…³ç³»æ–‡ä»¶ {relations_file} æ—¶å‡ºé”™: {e}")
                                continue
            
            if found:
                print(f"âœ… å…³ç³»åˆ é™¤æˆåŠŸ: {relation_id}")
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°å…³ç³»: {relation_id}")
                
        except Exception as e:
            print(f"âš ï¸ åˆ é™¤å…³ç³»æ—¶å‡ºé”™: {e}")
            return False
            
        return found
    
    # å¯è§†åŒ–æ•°æ®
    def get_graph_visualization_data(self, graph_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å›¾è°±å¯è§†åŒ–æ•°æ®"""
        try:
            graph = self.get_graph(graph_id)
            if not graph:
                return None
            
            entities = self.get_entities(graph_id)
            relations = self.get_relations(graph_id)
            
            # æ„å»ºvis-networkæ ¼å¼çš„æ•°æ®
            nodes = []
            edges = []
            
            # å®ä½“ç±»å‹é¢œè‰²æ˜ å°„
            type_colors = {
                "é’¢é“ææ–™": "#FF6B6B",
                "ç”Ÿäº§å·¥è‰º": "#4ECDC4",
                "æ€§èƒ½æŒ‡æ ‡": "#45B7D1",
                "åº”ç”¨é¢†åŸŸ": "#96CEB4",
                "è®¾å¤‡": "#FFEAA7",
                "ç¼ºé™·": "#DDA0DD",
                "åŒ–å­¦æˆåˆ†": "#98D8C8",
                "çƒ­å¤„ç†å·¥è‰º": "#F7DC6F",
                "æœºæ¢°æ€§èƒ½": "#BB8FCE",
                "è¡¨é¢å¤„ç†": "#85C1E9",
                "æ£€æµ‹æ–¹æ³•": "#F8C471"
            }
            
            # æ„å»ºèŠ‚ç‚¹
            for entity in entities:
                entity_type = entity.get("type") or entity.get("entity_type", "æœªçŸ¥")
                entity_desc = entity.get("description", "æ— æè¿°")
                color = type_colors.get(entity_type, "#BDC3C7")
                nodes.append({
                    "id": entity["id"],
                    "label": entity["name"],
                    "title": f"ç±»å‹: {entity_type}\næè¿°: {entity_desc}",
                    "color": color,
                    "size": min(20 + entity.get("frequency", 1) * 5, 50),
                    "font": {"size": 14},
                    "type": entity_type
                })
            
            # æ„å»ºè¾¹
            for relation in relations:
                relation_desc = relation.get("description", "æ— æè¿°")
                edges.append({
                    "id": relation["id"],
                    "from": relation["source_entity_id"],
                    "to": relation["target_entity_id"],
                    "label": relation["relation_type"],
                    "title": f"å…³ç³»: {relation['relation_type']}\nç½®ä¿¡åº¦: {relation['confidence']}\næè¿°: {relation_desc}",
                    "width": max(1, relation["confidence"] * 3),
                    "arrows": "to",
                    "color": {"color": "#848484", "highlight": "#FF6B6B"},
                    "font": {"size": 12}
                })
            
            return {
                "nodes": nodes,
                "edges": edges,
                "graph_info": graph
            }
            
        except Exception as e:
            raise e
    
    def get_category_visualization_data(self, category_id: str) -> Optional[Dict[str, Any]]:
        """è·å–åˆ†ç±»çš„å¯è§†åŒ–æ•°æ®ï¼ˆåŸºäºå®ä½“è·¯å¾„ç­›é€‰ï¼‰"""
        try:
            # è·å–å½“å‰åˆ†ç±»ä¿¡æ¯
            current_category = self.get_category(category_id)
            if not current_category:
                return None
            
            current_path = current_category.get("path", "/root")
            
            # è·å–æ‰€æœ‰å®ä½“ï¼Œæ ¹æ®è·¯å¾„ç­›é€‰
            all_entities = self.get_entities()
            filtered_entities = []
            
            for entity in all_entities:
                entity_path = entity.get("category_path", "/root")
                # æ£€æŸ¥å®ä½“è·¯å¾„æ˜¯å¦åŒ¹é…å½“å‰åˆ†ç±»è·¯å¾„
                if entity_path.startswith(current_path):
                    filtered_entities.append(entity)
            
            if not filtered_entities:
                return None
            
            # è·å–ç›¸å…³çš„å…³ç³»ï¼ˆåªåŒ…å«ç­›é€‰åå®ä½“ä¹‹é—´çš„å…³ç³»ï¼‰
            entity_ids = {entity["id"] for entity in filtered_entities}
            all_relations = self.get_relations()
            filtered_relations = [
                relation for relation in all_relations
                if relation["source_entity_id"] in entity_ids and relation["target_entity_id"] in entity_ids
            ]
            
            # å®ä½“ç±»å‹é¢œè‰²æ˜ å°„
            type_colors = {
                "é’¢é“ææ–™": "#FF6B6B",
                "ç”Ÿäº§å·¥è‰º": "#4ECDC4",
                "æ€§èƒ½æŒ‡æ ‡": "#45B7D1",
                "åº”ç”¨é¢†åŸŸ": "#96CEB4",
                "è®¾å¤‡": "#FFEAA7",
                "ç¼ºé™·": "#DDA0DD",
                "åŒ–å­¦æˆåˆ†": "#98D8C8",
                "çƒ­å¤„ç†å·¥è‰º": "#F7DC6F",
                "æœºæ¢°æ€§èƒ½": "#BB8FCE",
                "è¡¨é¢å¤„ç†": "#85C1E9",
                "æ£€æµ‹æ–¹æ³•": "#F8C471"
            }
            
            # æ„å»ºèŠ‚ç‚¹
            nodes = []
            entity_name_count = {}  # ç»Ÿè®¡åŒåå®ä½“æ•°é‡
            
            # å…ˆç»Ÿè®¡åŒåå®ä½“
            for entity in filtered_entities:
                name = entity["name"]
                entity_name_count[name] = entity_name_count.get(name, 0) + 1
            
            # å»é‡ï¼šå¯¹äºåŒåå®ä½“ï¼Œåªä¿ç•™ä¸€ä¸ªï¼Œä½†åˆå¹¶å…¶å±æ€§
            unique_entities = {}
            for entity in filtered_entities:
                name = entity["name"]
                if name not in unique_entities:
                    # è·å–å›¾è°±ä¿¡æ¯
                    graph = self.get_graph(entity["graph_id"]) if entity.get("graph_id") else None
                    graph_name = graph["name"] if graph else "æœªçŸ¥å›¾è°±"
                    
                    entity_type = entity.get("type") or entity.get("entity_type", "æœªçŸ¥")
                    entity_desc = entity.get("description", "æ— æè¿°")
                    color = type_colors.get(entity_type, "#BDC3C7")
                    
                    unique_entities[name] = {
                        "id": entity["id"],
                        "label": name,
                        "title": f"ç±»å‹: {entity_type}\næè¿°: {entity_desc}\nè·¯å¾„: {entity.get('category_path', '/root')}\næ¥æºå›¾è°±: {graph_name}\nå‡ºç°æ¬¡æ•°: {entity_name_count[name]}",
                        "color": color,
                        "size": min(20 + entity.get("frequency", 1) * 5 + entity_name_count[name] * 3, 60),
                        "font": {"size": 14},
                        "type": entity_type,
                        "category_path": entity.get("category_path", "/root"),
                        "occurrence_count": entity_name_count[name],
                        "source_graphs": [graph_name]
                    }
                else:
                    # åˆå¹¶æ¥æºå›¾è°±ä¿¡æ¯
                    graph = self.get_graph(entity["graph_id"]) if entity.get("graph_id") else None
                    graph_name = graph["name"] if graph else "æœªçŸ¥å›¾è°±"
                    if graph_name not in unique_entities[name]["source_graphs"]:
                        unique_entities[name]["source_graphs"].append(graph_name)
            
            nodes = list(unique_entities.values())
            
            # æ„å»ºè¾¹ï¼ˆéœ€è¦æ›´æ–°å®ä½“IDæ˜ å°„ï¼‰
            entity_id_mapping = {entity["id"]: unique_entities[entity["name"]]["id"] for entity in filtered_entities if entity["name"] in unique_entities}
            
            edges = []
            for relation in filtered_relations:
                source_id = entity_id_mapping.get(relation["source_entity_id"])
                target_id = entity_id_mapping.get(relation["target_entity_id"])
                
                if source_id and target_id and source_id != target_id:  # é¿å…è‡ªç¯
                    relation_desc = relation.get("description", "æ— æè¿°")
                    edges.append({
                        "id": relation["id"],
                        "from": source_id,
                        "to": target_id,
                        "label": relation["relation_type"],
                        "title": f"å…³ç³»: {relation['relation_type']}\nç½®ä¿¡åº¦: {relation['confidence']}\næè¿°: {relation_desc}",
                        "width": max(1, relation["confidence"] * 3),
                        "arrows": "to",
                        "color": {"color": "#848484", "highlight": "#FF6B6B"},
                        "font": {"size": 12}
                    })
            
            # åˆ›å»ºåˆ†ç±»è§†å›¾ä¿¡æ¯
            category_info = {
                "id": f"category_{category_id}",
                "name": f"åˆ†ç±»è§†å›¾ - {current_category['name']}",
                "description": f"è·¯å¾„: {current_path}ï¼ŒåŒ…å« {len(nodes)} ä¸ªå»é‡å®ä½“",
                "category_id": category_id,
                "category_path": current_path,
                "created_at": datetime.now().isoformat(),
                "is_category_view": True,
                "entity_count": len(nodes),
                "relation_count": len(edges)
            }
            
            return {
                "nodes": nodes,
                "edges": edges,
                "graph_info": category_info
            }
            
        except Exception as e:
            raise e
    
    # ç»Ÿè®¡ä¿¡æ¯
    def get_system_stats(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        graphs = self.get_all_graphs()
        entities = self.get_entities()
        relations = self.get_relations()
        
        # å®ä½“ç±»å‹ç»Ÿè®¡
        entity_type_stats = {}
        for entity in entities:
            entity_type = entity.get("type", "æœªçŸ¥ç±»å‹")
            entity_type_stats[entity_type] = entity_type_stats.get(entity_type, 0) + 1
        
        # å…³ç³»ç±»å‹ç»Ÿè®¡
        relation_type_stats = {}
        for relation in relations:
            relation_type = relation.get("relation_type", "æœªçŸ¥å…³ç³»")
            relation_type_stats[relation_type] = relation_type_stats.get(relation_type, 0) + 1
        
        return {
            "total_graphs": len(graphs),
            "total_entities": len(entities),
            "total_relations": len(relations),
            "entity_type_distribution": entity_type_stats,
            "relation_type_distribution": relation_type_stats,
            "recent_graphs": graphs[:5],  # æœ€è¿‘5ä¸ªå›¾è°±
            "system_health": "healthy",
            "last_updated": datetime.now().isoformat()
        }
    
    def _clear_graph_data(self, graph_id: str):
        """æ¸…ç†æŒ‡å®šå›¾è°±çš„åˆæ­¥å¤„ç†æ•°æ®ï¼ˆä¿ç•™æœ€ç»ˆæ¶ˆæ­§åçš„æ•°æ®ï¼‰"""
        print(f"ğŸ—‘ï¸ DataManager: æ¸…ç†å›¾è°± {graph_id} çš„åˆæ­¥å¤„ç†æ•°æ®...")
        
        # åªæ¸…ç†åˆæ­¥çš„å®ä½“è¯†åˆ«ç»“æœï¼ˆner_outputç›®å½•ä¸­çš„å›¾è°±ç‰¹å®šå­ç›®å½•ï¼‰
        ner_output_graph_dir = self.data_dir / "ner_output" / graph_id
        if ner_output_graph_dir.exists():
            for file_path in ner_output_graph_dir.glob("*.json"):
                file_path.unlink()
            print(f"âœ… DataManager: å·²æ¸…ç†åˆæ­¥å®ä½“è¯†åˆ«ç›®å½•: {ner_output_graph_dir}")
        
        # # æ¸…ç†æ–‡æœ¬åˆ†å—ç»“æœï¼ˆchunk_outputç›®å½•ä¸­çš„å›¾è°±ç‰¹å®šå­ç›®å½•ï¼‰
        # chunk_output_graph_dir = self.data_dir / "chunk_output" / graph_id
        # if chunk_output_graph_dir.exists():
        #     for file_path in chunk_output_graph_dir.glob("*.json"):
        #         file_path.unlink()
        #     print(f"âœ… DataManager: å·²æ¸…ç†æ–‡æœ¬åˆ†å—ç›®å½•: {chunk_output_graph_dir}")
        
        # # æ¸…ç†é¢„å¤„ç†æ–‡æœ¬ï¼ˆprocessed_textç›®å½•ä¸­çš„å›¾è°±ç‰¹å®šå­ç›®å½•ï¼‰
        # processed_text_graph_dir = self.data_dir / "processed_text" / graph_id
        # if processed_text_graph_dir.exists():
        #     for file_path in processed_text_graph_dir.glob("*"):
        #         if file_path.is_file():
        #             file_path.unlink()
        #     print(f"âœ… DataManager: å·²æ¸…ç†é¢„å¤„ç†æ–‡æœ¬ç›®å½•: {processed_text_graph_dir}")
        
        # æ³¨æ„ï¼šä¸æ¸…ç†æœ€ç»ˆçš„æ¶ˆæ­§åå®ä½“æ•°æ®ï¼ˆner_pro_outputï¼‰å’Œå…³ç³»æ•°æ®ï¼ˆre_outputï¼‰
        # è¿™äº›æ˜¯ç”¨æˆ·çš„æœ€ç»ˆå¤„ç†ç»“æœï¼Œåº”è¯¥ä¿ç•™
        
        print(f"âœ… DataManager: å›¾è°± {graph_id} çš„åˆæ­¥å¤„ç†æ•°æ®æ¸…ç†å®Œæˆï¼ˆä¿ç•™æœ€ç»ˆç»“æœï¼‰")
    
    # æ‰¹é‡å¯¼å…¥æ•°æ®
    def import_kg_data(self, graph_id: str, entities_data: List[Dict], relations_data: List[Dict]) -> Dict[str, Any]:
        """æ‰¹é‡å¯¼å…¥çŸ¥è¯†å›¾è°±æ•°æ®ï¼ˆé™„åŠ æ¨¡å¼ï¼šå…ˆæ¸…ç†æ—§æ•°æ®ï¼Œå†å¯¼å…¥æ–°æ•°æ®ï¼‰"""
        imported_entities = []
        imported_relations = []
        entity_id_mapping = {}  # åŸå§‹IDåˆ°æ–°IDçš„æ˜ å°„
        
        print(f"ğŸ”„ DataManager: å¼€å§‹å¯¼å…¥æ•°æ®åˆ°å›¾è°± {graph_id}")
        print(f"ğŸ“Š DataManager: å¾…å¯¼å…¥å®ä½“æ•°é‡: {len(entities_data)}")
        print(f"ğŸ“Š DataManager: å¾…å¯¼å…¥å…³ç³»æ•°é‡: {len(relations_data)}")
        
        # é™„åŠ æ¨¡å¼ï¼šå…ˆæ¸…ç†æ—§æ•°æ®
        self._clear_graph_data(graph_id)
        
        try:
            # å¯¼å…¥å®ä½“
            print(f"ğŸ”„ DataManager: å¼€å§‹å¯¼å…¥å®ä½“...")
            for i, entity_data in enumerate(entities_data):
                try:
                    new_entity = self.create_entity(
                        name=entity_data["name"],
                        entity_type=entity_data["type"],
                        description=entity_data.get("description", ""),
                        graph_id=graph_id
                    )
                    imported_entities.append(new_entity)
                    
                    # è®°å½•IDæ˜ å°„ï¼ˆå¦‚æœåŸå§‹æ•°æ®æœ‰IDï¼‰
                    if "id" in entity_data:
                        entity_id_mapping[entity_data["id"]] = new_entity["id"]
                    # ä¹Ÿå¯ä»¥é€šè¿‡åç§°æ˜ å°„
                    entity_id_mapping[entity_data["name"]] = new_entity["id"]
                    
                    if (i + 1) % 10 == 0 or i == 0:
                        print(f"ğŸ“ DataManager: å·²å¯¼å…¥å®ä½“ {i + 1}/{len(entities_data)}")
                        
                except Exception as e:
                    print(f"âŒ DataManager: å¯¼å…¥å®ä½“å¤±è´¥ {entity_data.get('name', 'Unknown')}: {e}")
                    continue
            
            print(f"âœ… DataManager: å®ä½“å¯¼å…¥å®Œæˆï¼ŒæˆåŠŸå¯¼å…¥ {len(imported_entities)} ä¸ªå®ä½“")
            
            # å¯¼å…¥å…³ç³»
            print(f"ğŸ”„ DataManager: å¼€å§‹å¯¼å…¥å…³ç³»...")
            for i, relation_data in enumerate(relations_data):
                try:
                    # æŸ¥æ‰¾å¯¹åº”çš„å®ä½“ID
                    source_id = None
                    target_id = None
                    source_name = relation_data.get("source_entity", "Unknown")
                    target_name = relation_data.get("target_entity", "Unknown")
                    
                    # å°è¯•é€šè¿‡ä¸åŒæ–¹å¼æ‰¾åˆ°å®ä½“ID
                    if "source_entity_id" in relation_data:
                        source_id = entity_id_mapping.get(relation_data["source_entity_id"])
                        if not source_id:
                            print(f"âš ï¸ DataManager: æ— æ³•é€šè¿‡IDæ‰¾åˆ°æºå®ä½“: {relation_data['source_entity_id']}")
                    if "target_entity_id" in relation_data:
                        target_id = entity_id_mapping.get(relation_data["target_entity_id"])
                        if not target_id:
                            print(f"âš ï¸ DataManager: æ— æ³•é€šè¿‡IDæ‰¾åˆ°ç›®æ ‡å®ä½“: {relation_data['target_entity_id']}")
                    
                    # å¦‚æœé€šè¿‡IDæ‰¾ä¸åˆ°ï¼Œå°è¯•é€šè¿‡åç§°æŸ¥æ‰¾
                    if not source_id and "source_entity" in relation_data:
                        source_id = entity_id_mapping.get(relation_data["source_entity"])
                        if not source_id:
                            print(f"âš ï¸ DataManager: æ— æ³•é€šè¿‡åç§°æ‰¾åˆ°æºå®ä½“: {source_name}")
                    if not target_id and "target_entity" in relation_data:
                        target_id = entity_id_mapping.get(relation_data["target_entity"])
                        if not target_id:
                            print(f"âš ï¸ DataManager: æ— æ³•é€šè¿‡åç§°æ‰¾åˆ°ç›®æ ‡å®ä½“: {target_name}")
                    
                    if source_id and target_id:
                        new_relation = self.create_relation(
                            source_entity_id=source_id,
                            target_entity_id=target_id,
                            relation_type=relation_data["relation_type"],
                            confidence=relation_data.get("confidence", 1.0),
                            description=relation_data.get("description", ""),
                            graph_id=graph_id
                        )
                        imported_relations.append(new_relation)
                    else:
                        print(f"âŒ DataManager: æ— æ³•åˆ›å»ºå…³ç³»ï¼Œç¼ºå°‘æºå®ä½“IDæˆ–ç›®æ ‡å®ä½“ID: {source_name} -> {target_name}")
                    
                    if (i + 1) % 10 == 0 or i == 0:
                        print(f"ğŸ“ DataManager: å·²å¤„ç†å…³ç³» {i + 1}/{len(relations_data)}")
                        
                except Exception as e:
                    print(f"âŒ DataManager: å¯¼å…¥å…³ç³»å¤±è´¥: {e}")
                    continue
                    
            print(f"âœ… DataManager: å…³ç³»å¯¼å…¥å®Œæˆï¼ŒæˆåŠŸå¯¼å…¥ {len(imported_relations)} ä¸ªå…³ç³»")
            
            return {
                "success": True,
                "imported_entities": len(imported_entities),
                "imported_relations": len(imported_relations),
                "entity_details": imported_entities,
                "relation_details": imported_relations
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "imported_entities": len(imported_entities),
                "imported_relations": len(imported_relations)
            }